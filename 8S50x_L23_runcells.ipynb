{"cells": [{"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 23: Markov Chain Monte Carlo - Part II</h1>\n", "\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_23_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L23.0 Overview</h2>\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_23_4\">L23.1 Quantum simulations</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_23_4\">L23.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_23_5\">L23.2 MCMC using a professional sampler</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_23_5\">L23.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_23_6\">L23.3 Gravitational Waves</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_23_6\">L23.3 Exercises</a></td>\n", "    </tr>\n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L23.0-runcell01\n", "\n", "!pip install corner\n", "!pip install lmfit\n", "!pip install bilby\n", "!pip install gwpy lalsuite"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L23.0-runcell01\n", "\n", "import imageio\n", "from PIL import Image\n", "\n", "import lmfit\n", "import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "import matplotlib.pyplot as plt\n", "import csv\n", "import math\n", "from scipy import optimize as opt\n", "from scipy import stats\n", "import matplotlib.cm as cm\n", "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n", "import corner\n", "\n", "import bilby\n", "import scipy.signal as sig\n", "from bilby.gw.source import lal_binary_black_hole\n", "from bilby.gw.conversion import convert_to_lal_binary_black_hole_parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L23.0-runcell02\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_23_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L23.1 Quantum Simulations </h2>  \n", "\n", "| [Top](#section_23_0) | [Previous Section](#section_23_3) | [Exercises](#exercises_23_4) | [Next Section](#section_23_5) |"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L23.1-runcell01\n", "\n", "def psi(ialpha,iR):\n", "    return np.where(iR > 0., ialpha*iR*np.exp(-ialpha*iR), 0.)#np.zeros(iR.shape))\n", "\n", "def prob(ialpha,iR,iNorm=-1):\n", "    if iR < 0:\n", "        return 0\n", "    if iNorm == -1:\n", "        rvals=np.arange(0.01,30,0.01)\n", "        iNorm = np.sum(psi(ialpha,rvals)**2*rvals)\n", "    return psi(ialpha,iR)**2/iNorm\n", "    \n", "def minE0(ialpha,iR):\n", "    return np.where(ialpha > 0, ialpha/iR -ialpha**2/2-1./iR, 0.)\n", "\n", "def expect(ialpha,irvals=np.arange(0.01,30,0.01)):\n", "    alphas, rvals = np.meshgrid(ialpha, irvals)\n", "    E0=np.sum(psi(alphas,rvals)*minE0(alphas,rvals)*psi(alphas,rvals),axis=0)\n", "    bot=np.sum(psi(alphas,rvals)*psi(alphas,rvals),axis=0)\n", "    return E0/bot\n", "\n", "rvals=np.arange(0.01,5,0.01)\n", "plt.plot(rvals,psi(0.5,rvals),label='0.5')\n", "plt.plot(rvals,psi(1.0,rvals),label='1.0')\n", "plt.plot(rvals,psi(1.5,rvals),label='1.5')\n", "plt.xlabel('r')\n", "plt.ylabel('$\\psi$')\n", "plt.legend()\n", "plt.show()\n", "\n", "alphas=np.arange(0.5,1.5,0.01)\n", "plt.plot(alphas,expect(alphas),label='alpha')\n", "plt.xlabel('alpha')\n", "plt.ylabel('E')\n", "plt.show()\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L23.1-runcell02\n", "\n", "def variational(ialpha=1.0,iR=1.0,iNSteps=2000,iStepSize=0.5,iNSamps=1000):\n", "    Rold=np.random.uniform(0,3,iNSamps)\n", "    for step in range(iNSteps):\n", "        rand=np.random.uniform(-1,1,iNSamps)\n", "        Rnew=Rold+rand*iStepSize\n", "        weight=(psi(ialpha,Rnew)/(psi(ialpha,Rold)+0.01))**2\n", "        randpos=np.random.uniform(0.01,1,iNSamps)\n", "        Rold = np.where(randpos < weight,Rnew,Rold)\n", "    return Rnew,expect(ialpha,Rnew)\n", "\n", "def variational_MCint(ialpha=1.0,iR=1.0,iNSteps=2000,iStepSize=0.5,iNSamps=1000):\n", "    Rold=np.random.uniform(0,3,iNSamps)\n", "    for step in range(iNSteps):\n", "        rand=np.random.uniform(-1,1,iNSamps)\n", "        Rnew=Rold+rand*iStepSize\n", "        weight=(psi(ialpha,Rnew)/(psi(ialpha,Rold)+0.01))**2\n", "        randpos=np.random.uniform(0.01,1,iNSamps)\n", "        Rold = np.where(randpos < weight,Rnew,Rold)\n", "    return Rnew,expect(ialpha,Rnew), np.mean(minE0(ialpha,Rold))\n", "\n", "R07,E07,E07exp=variational_MCint(0.7)\n", "R10,E10,E10exp=variational_MCint(1.0)\n", "R13,E13,E13exp=variational_MCint(1.3)\n", "\n", "_,bins,_ = plt.hist(R07,bins=20,alpha=0.5,label='0.7',density=True)\n", "plt.hist(R10,bins=bins,alpha=0.5,label='1.0',density=True)\n", "plt.hist(R13,bins=bins,alpha=0.5,label='1.3',density=True)\n", "plt.legend()\n", "plt.xlabel('r')\n", "plt.ylabel('N')\n", "plt.show()\n", "print(\"E\",E07,E10,E13)\n", "print(\"E-MC Integral\",E07exp,E10exp,E13exp)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L23.1-runcell03\n", "\n", "def expectFlat(ialpha,irvals=np.arange(0.01,30,0.01)):\n", "    E0=np.sum(psi(ialpha,irvals)*minE0(ialpha,irvals)*psi(ialpha,irvals),axis=0)\n", "    bot=np.sum(psi(ialpha,irvals)*psi(ialpha,irvals),axis=0)\n", "    return E0/bot\n", "\n", "def split(iAVals,iEVals):\n", "    arange = np.arange(0,3,0.2)\n", "    aesplit = []\n", "    for i0 in range(len(arange)-1):\n", "        avalL  = arange[i0]\n", "        avalM  = arange[i0+1]\n", "        pEVals = iEVals[(iAVals > avalL) & (iAVals < avalM) ]\n", "        aesplit.append(pEVals)\n", "    return arange, aesplit\n", "        \n", "def variational(iNSteps=25000,iStepSize=0.01,iNSamps=1000):\n", "    alphas=np.random.uniform(0.5,1.4,iNSamps)\n", "    Rold=np.random.uniform(0,3,iNSamps)\n", "    for step in range(iNSteps):\n", "        rand1=np.random.uniform(-1,1,iNSamps)\n", "        Rnew=Rold+rand1*iStepSize\n", "        rand2=np.random.uniform(-1,1,iNSamps)\n", "        alphasNew=alphas+rand2*iStepSize\n", "        weight1=(psi(alphas,Rnew)/(psi(alphas,Rold)+0.01))**2\n", "        #weight1=(psi(alphasNew,Rnew)/(psi(alphas,Rold)+0.01))**2\n", "        deltaE=minE0(alphas,Rold)-minE0(alphasNew,Rnew)\n", "        weight2=np.exp(0.1*deltaE)\n", "        randpos1=np.random.uniform(0.01,1,iNSamps)\n", "        randpos2=np.random.uniform(0.01,1,iNSamps)\n", "        Rold   = np.where(randpos1 < weight1,Rnew,Rold)\n", "        alphas = np.where(randpos2 < weight2,alphasNew,alphas)\n", "    return Rold,minE0(alphas,Rold),alphas\n", "\n", "R10,E10,A10=variational()\n", "\n", "plt.hist(E10,bins=bins,alpha=0.5)\n", "plt.xlabel('<E> (fitted)')\n", "plt.ylabel('N')\n", "plt.show()\n", "\n", "plt.hist(R10,bins=bins,alpha=0.5)\n", "plt.xlabel('r (fitted)')\n", "plt.ylabel('N')\n", "plt.show()\n", "\n", "plt.hist(A10,bins=bins,alpha=0.5)\n", "plt.xlabel('alpha (fitted)')\n", "plt.ylabel('N')\n", "plt.show()\n", "\n", "plt.plot(A10,E10,'.')\n", "plt.ylim(-10,5)\n", "plt.xlim(0,4)\n", "plt.ylabel('E$_{0}$')\n", "plt.xlabel('alpha')\n", "plt.show()\n", "\n", "\n", "ar,ae = split(A10,E10)\n", "ac    = 0.5*(ar[:-1] + ar[1:])\n", "plt.violinplot(ae, ac, widths=0.1, showmeans=True,showextrema=True, showmedians=False, bw_method=0.5)\n", "plt.ylabel('E$_{0}$')\n", "plt.xlabel('alpha')\n", "plt.show()\n", "\n", "print(\"E\",np.mean(E10))\n", "print(\"alpha\",np.mean(A10))\n", "print(\"r\",np.mean(R10))\n", "for i0,evals in enumerate(ae):\n", "    print(\"alpha:\",ac[i0],\"Emin\",np.mean(evals),\"std:\",np.std(evals))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L23.1-runcell04\n", "\n", "def variational(iNSteps=2000,iStepSize=0.5,iNSamps=10000):\n", "    alpharange=np.arange(0.5,1.5,0.1)\n", "    lNSamps = int(iNSamps/len(alpharange))    \n", "    alphas = np.array([])\n", "    for pAlpha in alpharange:\n", "        alrange = pAlpha*np.ones(lNSamps)\n", "        alphas = np.append(alphas,alrange)\n", "    Rold  =np.random.uniform(0,3,iNSamps)\n", "    for step in range(iNSteps):\n", "        rand1=np.random.uniform(-1,1,iNSamps)\n", "        Rnew=Rold+rand1*iStepSize\n", "        weight1=(psi(alphas,Rnew)/(psi(alphas,Rold)+0.01))**2\n", "        randpos1=np.random.uniform(0.01,1,iNSamps)\n", "        Rold   = np.where(randpos1 < weight1,Rnew,Rold)\n", "    return Rold,minE0(alphas,Rold),alphas\n", "\n", "\n", "def variationalOne(ialpha=1.0,iR=1.0,iNSteps=2000,iStepSize=0.5,iNSamps=1000):\n", "    Rold=np.random.uniform(0,3,iNSamps)\n", "    for step in range(iNSteps):\n", "        rand=np.random.uniform(-1,1,iNSamps)\n", "        Rnew=Rold+rand*iStepSize\n", "        weight=(psi(ialpha,Rnew)/(psi(ialpha,Rold)+0.01))**2\n", "        randpos=np.random.uniform(0.01,1,iNSamps)\n", "        Rold = np.where(randpos < weight,Rnew,Rold)\n", "    return Rnew,expect(ialpha,Rnew)\n", "\n", "\n", "R10,E10,A10=variational()\n", "R15,E15=variationalOne(1.5)\n", "plt.hist(R10[-1000:],bins=bins,alpha=0.5,label='1.0')\n", "plt.hist(R15,bins=bins,alpha=0.5,label='1.5')\n", "plt.xlabel('r')\n", "plt.ylabel('N')\n", "plt.legend()\n", "plt.show()\n", "\n", "\n", "ac = np.arange(0.5,1.5,0.1)\n", "ae = np.reshape(E10,(10,1000))\n", "ae1 = []\n", "ae2 = []\n", "for i0 in range(ae.shape[0]):\n", "    pR,pE=variationalOne(ac[i0])\n", "    ae1.append(pE)\n", "    ae2.append(ae[i0])\n", "plt.violinplot(ae1, ac, widths=0.1, showmeans=True,showextrema=True, showmedians=False, bw_method=0.5)\n", "plt.violinplot(ae2, ac, widths=0.1, showmeans=True,showextrema=True, showmedians=False, bw_method=0.5)\n", "plt.ylabel('E$_{0}$')\n", "plt.xlabel('alpha')\n", "plt.ylim(-0.75,-0.25)\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L23.1-runcell05\n", "\n", "#This is the simplified wavefunction without the beta term\n", "def psi(r,alpha,beta): #input r[0,0],r[0,1] = part 1 x and y => r[1,0],r[1,1] = part 2 x and y\n", "    r1 = np.sqrt(r[:,0,0]**2 + r[:,0,1]**2)\n", "    r2 = np.sqrt(r[:,1,0]**2 + r[:,1,1]**2)\n", "    return np.exp(-0.5*alpha*(r1+r2))\n", "\n", "def minE0(r,alpha,beta):  \n", "    r1 = np.sqrt(r[:,0,0]**2 + r[:,0,1]**2)\n", "    r2 = np.sqrt(r[:,1,0]**2 + r[:,1,1]**2)\n", "    r12 = np.sqrt((r[:,0,0]-r[:,1,0])**2 + (r[:,0,1]-r[:,1,1])**2)\n", "    #deno = 1.0/(1+beta*r12)\n", "    #deno2 = deno*deno\n", "    return (alpha-2)*(1./r1 + 1./r2) + 1./r12 -alpha**2 #+ 1.0/r12+deno2*(alpha*r12-deno2+2*beta*deno-1.0/r12)\n", "\n", "\n", "def variationalHe(ialpha=1.0,ibeta=1.0,iR=1.0,iNSteps=10000,iStepSize=0.5,iNSamps=1000):\n", "    Rold = np.zeros((iNSamps,2,2), np.double)\n", "    Rnew = np.zeros((iNSamps,2,2), np.double)\n", "    Rold = np.random.uniform(-1,1,Rold.shape)*iStepSize\n", "    for step in range(iNSteps):\n", "        rand=np.random.uniform(-1,1,Rold.shape)\n", "        Rnew=Rold+rand*iStepSize\n", "        weight=(psi(Rnew,ialpha,ibeta)/(psi(Rold,ialpha,ibeta)+0.01))**2\n", "        randpos=np.random.uniform(0.01,1,iNSamps)\n", "        updaterows = np.where(randpos < weight)\n", "        Rold[updaterows] = Rnew[updaterows]\n", "    return Rnew,minE0(Rnew,ialpha,ibeta)\n", "\n", "alphascan = np.arange(0.5,4.0,0.25)\n", "escan = []\n", "for alpha in alphascan:\n", "    print(alpha)\n", "    pR,pE=variationalHe(alpha)\n", "    escan.append(pE)\n", "\n", "plt.violinplot(escan, alphascan, widths=0.1, showmeans=True,showextrema=True, showmedians=False, bw_method=0.5)\n", "plt.ylabel('E$_{0}$')\n", "plt.xlabel('alpha')\n", "plt.ylim(-5,2)\n", "plt.show()\n", "\n", "pR,pE=variationalHe(alpha)\n", "plt.hist( np.sqrt(pR[:,0,0]**2 + pR[:,0,1]**2) )\n", "plt.xlabel(r'$\\sqrt{r_1^2 + r_2^2}$')\n", "plt.ylabel('N')\n", "plt.legend()\n", "plt.show()\n", "\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L23.1-runcell06\n", "\n", "#NOTE: running this cell will take several minutes (~15 min timed in Colab)\n", "\n", "#This is the full wavefunction with the beta term\n", "def psi(r,alpha,beta): #input r[0,0],r[0,1] = part 1 x and y => r[1,0],r[1,1] = part 2 x and y\n", "    r1 = np.sqrt(r[:,0,0]**2 + r[:,0,1]**2)\n", "    r2 = np.sqrt(r[:,1,0]**2 + r[:,1,1]**2)\n", "    r12 = np.sqrt((r[:,0,0]-r[:,1,0])**2 + (r[:,0,1]-r[:,1,1])**2)\n", "    d = r12/(1+beta*r12)\n", "    return np.exp(-0.5*alpha*(r1+r2)+0.5*d)\n", "\n", "def minE0(r,alpha,beta):  \n", "    r1 = np.sqrt(r[:,0,0]**2 + r[:,0,1]**2)\n", "    r2 = np.sqrt(r[:,1,0]**2 + r[:,1,1]**2)\n", "    r12 = np.sqrt((r[:,0,0]-r[:,1,0])**2 + (r[:,0,1]-r[:,1,1])**2)\n", "    dr12hatx = (r[:,0,0]/r1-r[:,1,0]/r2)*(r[:,0,0]-r[:,1,0])/r12#r12x*(r1x-r2x)\n", "    dr12haty = (r[:,0,1]/r1-r[:,1,1]/r2)*(r[:,0,1]-r[:,1,1])/r12#r12y*(r1y-r2y)\n", "    d    = 1.0/(1+beta*r12)\n", "    E1   = (alpha-2)*(1./r1 + 1./r2) + 1./r12 -alpha**2\n", "    E2   = (d**2)*(-1/r12 + beta*d - 0.25*d**2 + 0.5*alpha*(dr12hatx+dr12haty))\n", "    return E1 + E2\n", "\n", "def variationalHe(ialpha=1.0,ibeta=1.0,iR=1.0,iNSteps=10000,iStepSize=1.0,iNSamps=1000):\n", "    Rold = np.zeros((iNSamps,2,2), np.double)\n", "    Rnew = np.zeros((iNSamps,2,2), np.double)\n", "    Rold = np.random.uniform(-2,2,Rold.shape)*iStepSize\n", "    Eavg = np.zeros(iNSteps)\n", "    for step in range(iNSteps):\n", "        rand=np.random.uniform(-1,1,Rold.shape)\n", "        Rnew=Rold+rand*iStepSize\n", "        weight=(psi(Rnew,ialpha,ibeta)/(psi(Rold,ialpha,ibeta)))**2\n", "        randpos=np.random.uniform(0.0,1,iNSamps)\n", "        updaterows = np.where(randpos < weight)\n", "        Rold[updaterows] = Rnew[updaterows]\n", "        Eavg[step] = np.mean(minE0(Rold,ialpha,ibeta))\n", "    return Rold,minE0(Rold,ialpha,ibeta),Eavg\n", "\n", "alphascan = np.arange(0.5,4.0,0.25)\n", "betascan  = np.arange(0.0,2.0,0.125)\n", "#alphascan = np.arange(0.5,4.0,0.5)\n", "#betascan  = np.arange(0.0,2.0,1.0)\n", "coords = []\n", "escan = []\n", "X, Y = np.meshgrid(alphascan, betascan)\n", "eavg = np.zeros(X.shape)\n", "for i0,beta in enumerate(betascan):\n", "    for i1,alpha in enumerate(alphascan):\n", "        pR,pE,pEAvg=variationalHe(alpha,beta)\n", "        escan.append(pE)\n", "        eavg[i0,i1] = np.mean(pE[-2000:])\n", "        coords.append(np.array([alpha,beta]))\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L23.1-runcell07\n", "\n", "#make the plots from the data generated above!\n", "\n", "import matplotlib.cm as cm\n", "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n", "\n", "# Prepare for plots\n", "fig = plt.figure()\n", "ax = plt.axes(projection=\"3d\")\n", "# Plot the surface.\n", "surf = ax.plot_surface(X, Y, eavg,cmap=cm.coolwarm,linewidth=0, antialiased=False)\n", "# Customize the z axis.\n", "zmin = np.matrix(eavg).min()\n", "zmax = np.matrix(eavg).max()\n", "ax.set_zlim(zmin, zmax)\n", "ax.set_xlabel(r'$\\alpha$')\n", "ax.set_ylabel(r'$\\beta$')\n", "ax.set_zlabel(r'$\\langle E \\rangle$')\n", "ax.zaxis.set_major_locator(LinearLocator(10))\n", "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n", "# Add a color bar which maps values to colors.\n", "fig.colorbar(surf, shrink=0.5, aspect=5)\n", "plt.show()\n", "\n", "# Prepare for plots\n", "fig = plt.figure()\n", "ax = plt.axes()\n", "# Plot the surface.\n", "plt.pcolor(X, Y, eavg,cmap=cm.coolwarm)\n", "# Customize the z axis.\n", "ax.set_xlabel(r'$\\alpha$')\n", "ax.set_ylabel(r'$\\beta$')\n", "fig.colorbar(surf, shrink=0.5, aspect=5)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_23_4'></a>     \n", "\n", "| [Top](#section_23_0) | [Restart Section](#section_23_4) | [Next Section](#section_23_5) |\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 23.1.1</span>\n", "\n", "Let's look at our populated wavefunctions for two choices of parameters. Let's fix $\\beta$=1 and plot $p$ vs. $r_{12}$ for different values of $\\alpha$ (recall the definition $r_{12} = |\\vec{r_{1}} - \\vec{r_{2}}|$).\n", "\n", "Specifically, generate these plots for $\\alpha$=2 (lowest energy) and for $\\alpha$=4 (roughly the highest energy). What is the expected $r_{12}$ difference between the two electrons for each value $\\alpha$? Report both mean $r_{12}$ values as a list of two numbers `[rval_2, rval_4]` with precision 1e-1.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L23.1.1\n", "\n", "def plotProperties(ialpha=2,ibeta=1): \n", "    pR,pE,pEAvg=variationalHe(ialpha,ibeta)\n", "    r1=#your code\n", "    r2=#your cdoe\n", "    r12=#your code\n", "    \n", "    bins=np.arange(0,5,0.5)\n", "    plt.hist(r12,bins=bins,alpha=0.5,density=True)\n", "    plt.xlabel(\"r$_{12}$\")\n", "    plt.ylabel(\"p\")\n", "    plt.show()\n", "    print(\"Corr:\",np.corrcoef(r1,r2),\"Mean: r12\",np.mean(r12),\"E-avg (at end):\",pEAvg[-1])\n", "\n", "    rvals=np.vstack((r1,r2)).T\n", "    fig = corner.corner(rvals,show_titles=True,labels=['r$_1$','r$_2$'],plot_datapoints=True,quantiles=[0.16, 0.5, 0.84])\n", "    plt.show()\n", "\n", "\n", "plotProperties(2,1)\n", "plotProperties(4,1)"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_23_5'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L23.2 MCMC Using a Professional Sampler</h2>  \n", "\n", "| [Top](#section_23_0) | [Previous Section](#section_23_4) | [Exercises](#exercises_23_5) | [Next Section](#section_23_6) |"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_02"]}, "outputs": [], "source": ["#>>>RUN: L23.2-runcell01\n", "\n", "def model(x, m, c):\n", "    return m * x + c\n", "\n", "#make some toy data mx+c (m=1,c=0) smear y with sigma=0.1\n", "m = 1\n", "c = 0\n", "sigma = 0.1\n", "N = 100\n", "x = np.linspace(0, 1, N)\n", "y = model(x, m, c) + np.random.normal(0, sigma, N)\n", "\n", "#Now compute likelihood\n", "likelihood = bilby.core.likelihood.GaussianLikelihood(x, y, model,sigma=0.1)\n", "likelihood.parameters['m'] = 0.9\n", "likelihood.parameters['c'] = 0.1\n", "print(likelihood.log_likelihood())    \n", "\n", "plt.errorbar(x,y,yerr=0.1*np.ones(len(y)),marker='o',linestyle='dotted')\n", "plt.xlabel('x-value')\n", "plt.ylabel('y-value')\n", "plt.show()\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_02"]}, "outputs": [], "source": ["#>>>RUN: L23.2-runcell02\n", "\n", "#NOTE: running this cell will take several minutes\n", "\n", "priors = dict()\n", "priors['m'] = bilby.core.prior.Uniform(0, 5, 'm')\n", "priors['c'] = bilby.core.prior.Uniform(-2, 2, 'c')\n", "priors['sigma'] = sigma\n", "\n", "#uses dlogz=1\n", "full_result = bilby.run_sampler(likelihood=likelihood, priors=priors, sampler='dynesty', npoints=5000,outdir='test',dlogz=1, label='full')\n", "full_result.plot_corner()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_02"]}, "outputs": [], "source": ["#>>>RUN: L23.2-runcell03\n", "\n", "def model1(x,m2,m1,c):\n", "    return m2*x**2+m1*x+c\n", "\n", "likelihood = bilby.core.likelihood.GaussianLikelihood(x, y, model1,sigma=0.1)\n", "\n", "priors = dict()\n", "priors['c'] = bilby.core.prior.Uniform(-0.05, 0.05, 'c') #range change compared to video\n", "priors['m1'] = bilby.core.prior.Uniform(0, 6, 'm1')\n", "priors['m2'] = bilby.core.prior.Uniform(-2, 2, 'm2')\n", "priors['sigma'] = 0.1\n", "partial_result = bilby.run_sampler(likelihood=likelihood, priors=priors, sampler='dynesty', dlogz=1, npoints=500,outdir='tmp', label='tmpquad',check_point=False\n", ")\n", "partial_result.plot_corner()\n", "\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_23_5'></a>     \n", "\n", "| [Top](#section_23_0) | [Restart Section](#section_23_5) | [Next Section](#section_23_6) |\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 23.2.1</span>\n", "\n", "Ok, so to get confortable with advanced MCMC fitters, we are going to fit a similar datset to the one we fit in the previous lesson, a top hat function. As we did before, let's highlight several steps.\n", "\n", "<h3>Step 1: Generate Data</h3>\n", "\n", "Generate two sets of random data, that will ultimately create a top-hat shape. Run the following code to visualize this shape (note, this plotting code is not included in the code checker, but it is in the related notebook cell):\n", "\n", "<pre>\n", "#generate data\n", "np.random.seed(0)\n", "vals=np.random.rand(1000)*10\n", "vals=np.append(vals,np.random.rand(1000)*5 + 2.5)\n", "hist,bin_edges=np.histogram(vals,bins=np.arange(0,10.25,0.25))\n", "bin_centers=0.5*(bin_edges[:-1]+bin_edges[1:])\n", "plt.errorbar(bin_centers,hist,np.sqrt(hist),fmt='o', color='k')\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"events\")\n", "plt.show()\n", "</pre>\n", "\n", "\n", "<h3>Step 2: Define a Fit Function</h3>\n", "\n", "**Here is where the question comes in.** Now define a fit function with 3 parameters and a constant, like the following:\n", "\n", "$$\n", "f(x,a_0,x_0,c) = c + a_0 \\theta(x > (5-x_0)) - a_0 \\theta(x > (5+x_0))\n", "$$\n", "\n", "where $\\theta$ is the heaviside step function. Use the answer-checker below to submit your code.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L23.2.1\n", "\n", "#Generate the data -> just run this code if \n", "#you want to see what it looks like first\n", "#-----------------------------------------------\n", "np.random.seed(0)\n", "vals=np.random.rand(1000)*10\n", "vals=np.append(vals,np.random.rand(1000)*5 + 2.5)\n", "hist,bin_edges=np.histogram(vals,bins=np.arange(0,10.25,0.25))\n", "bin_centers=0.5*(bin_edges[:-1]+bin_edges[1:])\n", "plt.errorbar(bin_centers,hist,np.sqrt(hist),fmt='o', color='k')\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"events\")\n", "plt.show()\n", "\n", "\n", "#define the step-function used for fitting\n", "#-----------------------------------------------\n", "def model(x,a0,x0,c):\n", "    val = ### Your formula\n", "    return val\n", "\n", "\n", "#optionally, plot the fit function for some random parameter choices:\n", "#-----------------------------------------------\n", "\n", "# Define the range of x values\n", "x_values = np.linspace(1, 10, 1000)  # x goes from 1 to 10 with 1000 points\n", "\n", "# Define the parameters for the model\n", "a0 = 2    # Amplitude of the step\n", "x0 = 1    # Offset from the center (x=5)\n", "c = 0     # Constant offset\n", "\n", "# Calculate the output of the function for these parameters\n", "y_values = model(x_values, a0, x0, c)\n", "\n", "# Plot the result\n", "plt.figure(figsize=(10, 6))\n", "plt.plot(x_values, y_values, label=f'a0={a0}, x0={x0}, c={c}')\n", "plt.xlabel('x')\n", "plt.ylabel('Function Value')\n", "plt.title('Plot of the model function')\n", "plt.legend()\n", "plt.grid(True)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 23.2.2</span>\n", "\n", "<h3>Step 3: Perform the Fit</h3>\n", "\n", "Now we will run the fit using `bilby`. Complete the code below to perform the fit. To do this you must:\n", "\n", "- Define a set of uniform priors for the parameters as follows: `c` over the range `[0,100]`, `x0` over the range `[0,10]`, `a0` over the range `[0,100]`. One of these is done for you!\n", "\n", "- Define the uncertainties on the parameters. Again, one of these is done for you.\n", "\n", "Note, to get the fit to work, we set `dlogz=10`. This is the change in the log likelihood per MC step, and ideally we want to get this to be below 1, but that can take quite a long time. Still, the code will take about 10 min to run (timed in Colab).\n", "\n", "After running the fit, report the uncertainty that you find on `x0` as a number with precision `1e-2`.  \n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L23.2.2\n", "\n", "likelihood = bilby.core.likelihood.GaussianLikelihood(bin_centers, hist, model,sigma=np.sqrt(hist))\n", "priors['c']  = bilby.core.prior.Uniform(0, 100, 'c')\n", "priors['x0'] = #YOUR CODE HERE\n", "priors['a0'] = #YOUR CODE HERE\n", "\n", "partial_result = bilby.run_sampler(likelihood=likelihood, priors=priors, sampler='dynesty', dlogz=10, npoints=5000,outdir='t0', label='base2',check_point=False)\n", "partial_result.plot_corner()\n", "#partial_result.plot_with_data(model, bin_centers, hist)\n", "\n", "cbst  = partial_result.posterior[\"c\"].mean()\n", "a0bst = partial_result.posterior[\"a0\"].mean()\n", "x0bst = partial_result.posterior[\"x0\"].mean()\n", "\n", "cunc  = partial_result.posterior[\"c\"].std()\n", "a0unc = #YOUR CODE HERE\n", "x0unc = #YOUR CODE HERE\n", "\n", "print(\"c:\",  cbst,\"+/-\",cunc)\n", "print(\"a0:\",a0bst,\"+/-\",a0unc)\n", "print(\"x0:\",x0bst,\"+/-\",x0unc)\n", "\n", "\n", "yvals=model(bin_centers,a0bst,x0bst,cbst)\n", "plt.errorbar(bin_centers,hist,np.sqrt(hist),fmt='o', color='k')\n", "plt.plot(bin_centers,yvals,c='r')\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"events\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 23.2.3</span>\n", "\n", "Alright now lets generalize this to have more parameters and examine their correlations. Update the function with the form below: \n", "\n", "$$\n", "f(x,a0,x0,c) = c + a0 \\theta(x > x0) + a1 \\theta(x > x1)\n", "$$\n", "\n", "where $\\theta$ is the heaviside step function. Use the answer-checker below to submit your code. \n", "\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L23.2.3\n", "\n", "#Generate the data -> just run this code if \n", "#you want to see what it looks like first\n", "#-----------------------------------------------\n", "np.random.seed(0)\n", "vals=np.random.rand(1000)*10\n", "vals=np.append(vals,np.random.rand(1000)*5 + 2.5)\n", "#vals=np.append(vals,np.random.rand(1000)*2+4.)\n", "hist,bin_edges=np.histogram(vals,bins=np.arange(0,10.25,0.25))\n", "bin_centers=0.5*(bin_edges[:-1]+bin_edges[1:])\n", "plt.errorbar(bin_centers,hist,np.sqrt(hist),fmt='o', color='k')\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"events\")\n", "plt.show()\n", "\n", "\n", "#define the step-function used for fitting\n", "#-----------------------------------------------\n", "def model(x,a0,x0,a1,x1,c):\n", "    val= #YOUR CODE HERE\n", "    return val\n", "\n", "\n", "#optionally, plot the fit function for some random parameter choices:\n", "#-----------------------------------------------\n", "\n", "# Define the range of x values\n", "x_values = np.linspace(1, 10, 1000)  # x goes from 1 to 10 with 1000 points\n", "\n", "# Define the parameters for the model\n", "a0 = 2    # Amplitude of the first step\n", "x0 = 4    # Position of the first step\n", "a1 = -3   # Amplitude of the second step\n", "x1 = 7    # Position of the second step\n", "c = 0.5   # Constant offset\n", "\n", "# Calculate the output of the function for these parameters\n", "y_values = model(x_values, a0, x0, a1, x1, c)\n", "\n", "# Plot the result\n", "plt.figure(figsize=(10, 6))\n", "plt.plot(x_values, y_values, label=f'a0={a0}, x0={x0}, a1={a1}, x1={x1}, c={c}')\n", "plt.xlabel('x')\n", "plt.ylabel('Function Value')\n", "plt.title('Plot of the new model function')\n", "plt.legend()\n", "plt.grid(True)\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 23.2.4</span>\n", "\n", "Now we will run the fit using `bilby`. Complete the code below to perform the fit. To do this you must:\n", "\n", "- Define a set of uniform priors for the parameters as follows: `c` over the range `[0, 100]`, `x0` over the range `[0, 10]`, `x1` over the range `[0, 10]`, `a0` over the range `[0, 100]`, and `a1` over the range `[-100, 0]`.\n", "\n", "- Define the uncertainties on the parameters.\n", "\n", "To get the fit to work, set `dlogz=50`. Additionally, we will add a constraint requiring `x1 > x0` to do this, we create a new variable `x10=x1-x0` and we put a constriant on this. \n", "\n", "After running the code, which varaibles appear correlated in the corner plot? Select ALL that apply.\n", "\n", "A) `x0` and `c`\\\n", "B) `x1` and `c`\\\n", "C) `a0` and `c`\\\n", "D) `a1` and `c`\\\n", "E) `x0` and `x1`\\\n", "F) `x0` and `a0`\\\n", "G) `x0` and `a1`\\\n", "H) `x1` and `a0`\\\n", "I) `x1` and `a1`\\\n", "J) `a0` and `a1`\n", "\n", "\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L23.2.4\n", "\n", "from bilby.core.prior import PriorDict, Uniform, Constraint\n", "\n", "likelihood = bilby.core.likelihood.GaussianLikelihood(bin_centers, hist, model,sigma=np.sqrt(hist))\n", "#likelihood = bilby.core.likelihood.PoissonLikelihood(bin_centers, hist, model,sigma=np.sqrt(hist))\n", "\n", "def conv_constraint(parameters):\n", "    parameters['x10'] = parameters['x1'] - parameters['x0']\n", "    return parameters\n", "\n", "priors = PriorDict(conversion_function=conv_constraint)\n", "priors['c']  = #YOUR CODE HERE\n", "priors['x0'] = #YOUR CODE HERE\n", "priors['x1'] = #YOUR CODE HERE\n", "priors['a0'] = #YOUR CODE HERE\n", "priors['a1'] = #YOUR CODE HERE\n", "priors['x10'] = Constraint(minimum=0, maximum=10)\n", "\n", "partial_result = bilby.run_sampler(likelihood=likelihood, priors=priors, sampler='dynesty', dlogz=100, npoints=5000,outdir='t0', label='base_big1',check_point=False)\n", "partial_result.plot_corner()\n", "\n", "\n", "cbst  = partial_result.posterior[\"c\"].mean()\n", "a0bst = partial_result.posterior[\"a0\"].mean()\n", "x0bst = partial_result.posterior[\"x0\"].mean()\n", "a1bst = partial_result.posterior[\"a1\"].mean()\n", "x1bst = partial_result.posterior[\"x1\"].mean()\n", "\n", "cunc  = #YOUR CODE HERE\n", "a0unc = #YOUR CODE HERE\n", "x0unc = #YOUR CODE HERE\n", "a1unc = #YOUR CODE HERE\n", "x1unc = #YOUR CODE HERE\n", "\n", "print(\"c:\",  cbst,\"+/-\",cunc)\n", "print(\"a0:\",a0bst,\"+/-\",a0unc)\n", "print(\"x0:\",x0bst,\"+/-\",x0unc)\n", "print(\"a1:\",a1bst,\"+/-\",a1unc)\n", "print(\"x1:\",x1bst,\"+/-\",x1unc)\n", "\n", "yvals=model(bin_centers,a0bst,x0bst,a1bst,x1bst,cbst)\n", "plt.errorbar(bin_centers,hist,np.sqrt(hist),fmt='o', color='k')\n", "plt.plot(bin_centers,yvals,c='r')\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"events\")\n", "plt.show()\n", "\n", "partial_result.plot_corner()"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_23_6'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L23.3 Gravitational Waves </h2>  \n", "\n", "| [Top](#section_23_0) | [Previous Section](#section_23_5) | [Exercises](#exercises_23_6) |"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L23.3-runcell01\n", "\n", "duration = 4.#4s\n", "sampling_frequency = 2048.#Hz\n", "waveform_arguments = {\n", "    'waveform_approximant': 'IMRPhenomPv2',\n", "    'reference_frequency': 50.,  # most sensitive frequency\n", "    'minimum_frequency': 20.\n", "}\n", "waveform_generator = bilby.gw.WaveformGenerator(\n", "    duration=duration, sampling_frequency=sampling_frequency,\n", "    parameter_conversion=convert_to_lal_binary_black_hole_parameters,\n", "    frequency_domain_source_model=lal_binary_black_hole,\n", "    waveform_arguments=waveform_arguments)\n", "\n", "def generateWaveForm(iM1,iM2):\n", "    injection_parameters = dict(\n", "    mass_1=iM1, mass_2=iM2, a_1=0., a_2=0., tilt_1=0., tilt_2=0.,\n", "    phi_12=0., phi_jl=0., luminosity_distance=500, theta_jn=0., psi=0.,\n", "    phase=0.2, geocent_time=1243309096, ra=0., dec=0.)\n", "    polarizations_td = waveform_generator.time_domain_strain(injection_parameters)\n", "    return polarizations_td\n", "\n", "def shiftplus(iPolar,sampling,duration):\n", "    plus_td  = np.roll(iPolar['plus'],  int(sampling * duration/2.))\n", "    cross_td = np.roll(iPolar['cross'], int(sampling * duration/2.))\n", "    return plus_td\n", "    \n", "polarizations_td0 = generateWaveForm(50,50)\n", "polarizations_td1 = generateWaveForm(10,50)\n", "polarizations_td2 = generateWaveForm(100,50)\n", "\n", "plus_td0=shiftplus(polarizations_td0,sampling_frequency,duration)\n", "plus_td1=shiftplus(polarizations_td1,sampling_frequency,duration)\n", "plus_td2=shiftplus(polarizations_td2,sampling_frequency,duration)\n", "\n", "time = np.linspace(0.,duration,len(plus_td0))\n", "\n", "plt.plot(time, plus_td0, label='plus 50,50')\n", "plt.plot(time, plus_td1, label='plus 10,50')\n", "plt.plot(time, plus_td2, label='plus 100,50')\n", "plt.legend()\n", "plt.show()\n", "\n", "plt.plot(time, plus_td0, label='plus 50,50')\n", "plt.plot(time, plus_td1, label='plus 10,50')\n", "plt.plot(time, plus_td2, label='plus 100,50')\n", "plt.legend()\n", "plt.xlim(1.7,2.1)\n", "plt.show()\n", "\n", "# And their ASD\n", "def asd(its):\n", "    NFFT = int(4 * sampling_frequency)\n", "    freq, plus_psd = sig.welch(its, fs=sampling_frequency, nperseg=NFFT)\n", "    plus_asd = np.sqrt(plus_psd)\n", "    return freq, plus_asd\n", "\n", "freq, plus_asd0 = asd(plus_td0)\n", "freq, plus_asd1 = asd(plus_td1)\n", "freq, plus_asd2 = asd(plus_td2)\n", "\n", "fig = plt.figure(figsize=(8, 5))\n", "plt.loglog(freq, plus_asd0, label='Plus')\n", "plt.loglog(freq, plus_asd1, label='Plus')\n", "plt.loglog(freq, plus_asd2, label='Plus')\n", "plt.xlim(10, 1024)\n", "plt.xlabel('Frequency [Hz]')\n", "plt.ylabel('ASD')\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L23.3-runcell02\n", "\n", "from gwpy.timeseries import TimeSeries\n", "\n", "time_of_event = 1126259462.413\n", "\n", "H1 = bilby.gw.detector.get_empty_interferometer(\"H1\")\n", "L1 = bilby.gw.detector.get_empty_interferometer(\"L1\")\n", "\n", "# Definite times in relatation to the trigger time (time_of_event), duration and post_trigger_duration\n", "post_trigger_duration = 2\n", "duration = 4\n", "analysis_start = time_of_event + post_trigger_duration - duration\n", "#ok so get the data we are going to use for the fit\n", "H1_analysis_data = TimeSeries.fetch_open_data(\"H1\", analysis_start, analysis_start + duration, sample_rate=4096, cache=True)\n", "L1_analysis_data = TimeSeries.fetch_open_data(\"L1\", analysis_start, analysis_start + duration, sample_rate=4096, cache=True)\n", "\n", "# Use gwpy to fetch the open data and get the data around the time to compute the psd\n", "psd_duration = duration * 32\n", "psd_start_time = analysis_start - psd_duration\n", "H1_psd_data = TimeSeries.fetch_open_data( \"H1\", psd_start_time, psd_start_time + psd_duration, sample_rate=4096, cache=True)\n", "L1_psd_data = TimeSeries.fetch_open_data( \"L1\", psd_start_time, psd_start_time + psd_duration, sample_rate=4096, cache=True)\n", "plt.plot(H1_psd_data)\n", "plt.plot(L1_psd_data)\n", "plt.plot(H1_analysis_data)\n", "plt.plot(L1_analysis_data)\n", "plt.show()\n", "\n", "#Set this to our model\n", "H1.set_strain_data_from_gwpy_timeseries(H1_analysis_data)\n", "L1.set_strain_data_from_gwpy_timeseries(L1_analysis_data)\n", "\n", "#Now compute the PSDs and set this \n", "psd_alpha = 2 * H1.strain_data.roll_off / duration\n", "H1_psd = H1_psd_data.psd(fftlength=duration, overlap=0, window=(\"tukey\", psd_alpha), method=\"median\")\n", "L1_psd = L1_psd_data.psd(fftlength=duration, overlap=0, window=(\"tukey\", psd_alpha), method=\"median\")\n", "H1.power_spectral_density = bilby.gw.detector.PowerSpectralDensity(frequency_array=H1_psd.frequencies.value, psd_array=H1_psd.value)\n", "L1.power_spectral_density = bilby.gw.detector.PowerSpectralDensity(frequency_array=L1_psd.frequencies.value, psd_array=L1_psd.value)\n", "\n", "fig, ax = plt.subplots()\n", "idxs = H1.strain_data.frequency_mask  # This is a boolean mask of the frequencies which we'll use in the analysis\n", "ax.loglog(H1.strain_data.frequency_array[idxs],np.abs(H1.strain_data.frequency_domain_strain[idxs]))\n", "ax.loglog(H1.power_spectral_density.frequency_array[idxs], H1.power_spectral_density.asd_array[idxs])\n", "ax.set_title(\"Hanford\")\n", "ax.set_xlabel(\"Frequency [Hz]\")\n", "ax.set_ylabel(\"Strain [strain/$\\sqrt{Hz}$]\")\n", "plt.show()\n", "\n", "H1.maximum_frequency = 1024\n", "L1.maximum_frequency = 1024\n", "\n", "fig, ax = plt.subplots()\n", "idxs = L1.strain_data.frequency_mask  # This is a boolean mask of the frequencies which we'll use in the analysis\n", "ax.loglog(L1.strain_data.frequency_array[idxs],np.abs(L1.strain_data.frequency_domain_strain[idxs]))\n", "ax.loglog(L1.power_spectral_density.frequency_array[idxs], L1.power_spectral_density.asd_array[idxs])\n", "ax.set_title(\"Livingston\")\n", "ax.set_xlabel(\"Frequency [Hz]\")\n", "ax.set_ylabel(\"Strain [strain/$\\sqrt{Hz}$]\")\n", "plt.show()\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L23.3-runcell03\n", "\n", "# First, put our \"data\" created above into a list of interferometers (the order is arbitrary)\n", "interferometers = [H1, L1]\n", "\n", "# Next create a dictionary of arguments which we pass into the LALSimulation waveform - we specify the waveform approximant here\n", "waveform_arguments = dict(waveform_approximant='IMRPhenomPv2', \n", "                          reference_frequency=100., catch_waveform_errors=True)\n", "\n", "# Next, create a waveform_generator object. This wraps up some of the jobs of converting between parameters etc\n", "waveform_generator = bilby.gw.WaveformGenerator(\n", "    frequency_domain_source_model=bilby.gw.source.lal_binary_black_hole,\n", "    waveform_arguments=waveform_arguments,\n", "    parameter_conversion=convert_to_lal_binary_black_hole_parameters)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L23.3-runcell04\n", "\n", "#NOTE: running this cell will take several minutes (~30 min timed in Colab)\n", "\n", "from bilby.core.prior import Uniform\n", "\n", "prior = bilby.core.prior.PriorDict()\n", "prior['chirp_mass'] = Uniform(name='chirp_mass', minimum=25.0,maximum=35.5)\n", "prior['mass_ratio'] = Uniform(name='mass_ratio', minimum=0.5, maximum=1)\n", "prior['phase']        = 1.3#Uniform(name=\"phase\", minimum=0, maximum=2*np.pi)\n", "prior['geocent_time'] = Uniform(name=\"geocent_time\", minimum=time_of_event-0.1, maximum=time_of_event+0.1)\n", "prior['a_1'] =  0.0\n", "prior['a_2'] =  0.0\n", "prior['tilt_1'] =  0.0\n", "prior['tilt_2'] =  0.0\n", "prior['phi_12'] =  0.0\n", "prior['phi_jl'] =  0.0\n", "prior['dec'] =  -1.2232\n", "prior['ra'] =  2.19432\n", "prior['theta_jn'] =  1.89694\n", "prior['psi'] =  0.532268\n", "prior['luminosity_distance'] = 412.066\n", "\n", "# Finally, create our likelihood, passing in what is needed to get going\n", "likelihood = bilby.gw.likelihood.GravitationalWaveTransient(interferometers, waveform_generator, priors=prior,\n", "    time_marginalization=True, phase_marginalization=False, distance_marginalization=False)\n", "\n", "result_short = bilby.run_sampler(\n", "    likelihood, prior, sampler='dynesty', outdir='short3', label=\"GW150914\",\n", "    conversion_function=bilby.gw.conversion.generate_all_bbh_parameters,\n", "    sample=\"unif\", nlive=500, dlogz=3  # <- Arguments are used to make things fast - not recommended for general use\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L23.3-runcell05\n", "\n", "result_short.plot_corner(parameters=[\"chirp_mass\", \"mass_ratio\", \"geocent_time\"], prior=True)\n", "#plt.show()\n", "#print(result_short.posterior)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L23.3-runcell06\n", "\n", "from bilby.gw.result import CBCResult\n", "\n", "cbc_result = CBCResult.from_json(\"short3/GW150914_result.json\")\n", "for ifo in interferometers:\n", "    cbc_result.plot_interferometer_waveform_posterior(\n", "        interferometer=ifo, n_samples=500, save=False\n", "    )\n", "    plt.show()\n", "    plt.close()\n", "    \n", "print(result_short)\n", "#result_short.plot_marginals()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L23.3-runcell07\n", "\n", "#NOTE: running this cell will take several minutes (~30 min timed in Colab)\n", "\n", "prior = bilby.core.prior.PriorDict()\n", "prior['chirp_mass']   = Uniform(name='chirp_mass', minimum=25.0,maximum=35.5)\n", "prior['mass_ratio']   = Uniform(name='mass_ratio', minimum=0.5, maximum=1)\n", "prior['phase']        = Uniform(name=\"phase\", minimum=0, maximum=2*np.pi)\n", "prior['geocent_time'] = Uniform(name=\"geocent_time\", minimum=time_of_event-0.1, maximum=time_of_event+0.1)\n", "prior['a_1'] =  0.0\n", "prior['a_2'] =  0.0\n", "prior['tilt_1'] =  0.0\n", "prior['tilt_2'] =  0.0\n", "prior['phi_12'] =  0.0\n", "prior['phi_jl'] =  0.0\n", "prior['dec'] =  -1.2232\n", "prior['ra'] =  2.19432\n", "prior['theta_jn'] =  1.89694\n", "prior['psi'] =  0.532268\n", "prior['luminosity_distance'] = bilby.core.prior.PowerLaw(alpha=2., minimum=50., maximum=800., name='luminosity_distance')\n", "\n", "# Finally, create our likelihood, passing in what is needed to get going\n", "likelihood = bilby.gw.likelihood.GravitationalWaveTransient(interferometers, waveform_generator, priors=prior,\n", "    time_marginalization=True, phase_marginalization=True, distance_marginalization=True)\n", "\n", "result_short = bilby.run_sampler(\n", "    likelihood, prior, sampler='dynesty', outdir='short_dist', label=\"GW150914\",\n", "    conversion_function=bilby.gw.conversion.generate_all_bbh_parameters,\n", "    sample=\"unif\", nlive=500, dlogz=3  # <- Arguments are used to make things fast - not recommended for general use\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L23.3-runcell08\n", "\n", "result_short.plot_corner(parameters=[\"chirp_mass\", \"mass_ratio\", \"geocent_time\",\"luminosity_distance\",\"phase\"], prior=True)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L23.3-runcell09\n", "\n", "from bilby.gw.result import CBCResult\n", "\n", "cbc_result = CBCResult.from_json(\"short_dist/GW150914_result.json\")\n", "for ifo in interferometers:\n", "    cbc_result.plot_interferometer_waveform_posterior(\n", "        interferometer=ifo, n_samples=500, save=False\n", "    )\n", "    plt.show()\n", "    plt.close()\n", "    \n", "print(cbc_result.log_likelihood_evaluations)\n", "#result_short.plot_marginals()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L23.3-runcell10\n", "\n", "plt.hist(cbc_result.log_likelihood_evaluations)\n", "plt.show()\n", "print(cbc_result.log_bayes_factor)"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_23_6'></a>     \n", "\n", "| [Top](#section_23_0) | [Restart Section](#section_23_6) | \n"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 23.3.1</span>\n", "\n", "Now let's fix the mass ratio to 0.5 instead of floating it. Run the code below to find the chirp mass and report your answer as a number with a precision of one solar mass unit.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L23.3.1\n", "\n", "from bilby.core.prior import Uniform\n", "\n", "prior = bilby.core.prior.PriorDict()\n", "prior['chirp_mass'] = Uniform(name='chirp_mass', minimum=25.0,maximum=35.5)\n", "prior['mass_ratio'] = #YOUR CODE HERE\n", "prior['phase']        = 1.3#Uniform(name=\"phase\", minimum=0, maximum=2*np.pi)\n", "prior['geocent_time'] = Uniform(name=\"geocent_time\", minimum=time_of_event-0.1, maximum=time_of_event+0.1)\n", "prior['a_1'] =  0.0\n", "prior['a_2'] =  0.0\n", "prior['tilt_1'] =  0.0\n", "prior['tilt_2'] =  0.0\n", "prior['phi_12'] =  0.0\n", "prior['phi_jl'] =  0.0\n", "prior['dec'] =  -1.2232\n", "prior['ra'] =  2.19432\n", "prior['theta_jn'] =  1.89694\n", "prior['psi'] =  0.532268\n", "prior['luminosity_distance'] = 412.066\n", "\n", "# Finally, create our likelihood, passing in what is needed to get going\n", "likelihood = bilby.gw.likelihood.GravitationalWaveTransient(interferometers, waveform_generator, priors=prior,\n", "    time_marginalization=True, phase_marginalization=False, distance_marginalization=False)\n", "\n", "result_short = bilby.run_sampler(\n", "    likelihood, prior, sampler='dynesty', outdir='short4', label=\"GW150914\",\n", "    conversion_function=bilby.gw.conversion.generate_all_bbh_parameters,\n", "    sample=\"unif\", nlive=500, dlogz=3  #Arguments are used to make things fast - not recommended for general use\n", ")\n", "\n", "result_short.plot_corner(parameters=[\"chirp_mass\", \"geocent_time\"], prior=True)"]}, {"cell_type": "markdown", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 23.3.2</span>\n", "\n", "The choice of priors yields different interpretations of gravitational wave events. Lets re-run the fit that we performed earlier in this section, using a flat prior for the luminosity distance. Recall our previous result for the luminosity distance was about 299 Mpc, using a power law.\n", "\n", "How does a flat prior change our result for the luminosity distance that is found? Report your answer with a precision of one Mpc.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L23.3.2\n", "\n", "#NOTE: running this cell will take several minutes\n", "\n", "prior = bilby.core.prior.PriorDict()\n", "prior['chirp_mass']   = Uniform(name='chirp_mass', minimum=25.0,maximum=35.5)\n", "prior['mass_ratio']   = Uniform(name='mass_ratio', minimum=0.5, maximum=1)\n", "prior['phase']        = Uniform(name=\"phase\", minimum=0, maximum=2*np.pi)\n", "prior['geocent_time'] = Uniform(name=\"geocent_time\", minimum=time_of_event-0.1, maximum=time_of_event+0.1)\n", "prior['a_1'] =  0.0\n", "prior['a_2'] =  0.0\n", "prior['tilt_1'] =  0.0\n", "prior['tilt_2'] =  0.0\n", "prior['phi_12'] =  0.0\n", "prior['phi_jl'] =  0.0\n", "prior['dec'] =  -1.2232\n", "prior['ra'] =  2.19432\n", "prior['theta_jn'] =  1.89694\n", "prior['psi'] =  0.532268\n", "prior['luminosity_distance'] = Uniform(minimum=50., maximum=800., name='luminosity_distance')\n", "\n", "# Finally, create our likelihood, passing in what is needed to get going\n", "likelihood = bilby.gw.likelihood.GravitationalWaveTransient(interferometers, waveform_generator, priors=prior,\n", "    time_marginalization=True, phase_marginalization=True, distance_marginalization=True)\n", "\n", "result_short = bilby.run_sampler(\n", "    likelihood, prior, sampler='dynesty', outdir='short_dist_flat', label=\"GW150914\",\n", "    conversion_function=bilby.gw.conversion.generate_all_bbh_parameters,\n", "    sample=\"unif\", nlive=500, dlogz=3  # <- Arguments are used to make things fast - not recommended for general use\n", ")\n", "\n", "result_short.plot_corner(parameters=[\"chirp_mass\", \"mass_ratio\", \"geocent_time\",\"luminosity_distance\",\"phase\"], prior=True)\n"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}