{"cells": [{"cell_type": "markdown", "id": "1ee373c5", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 18: Numerical ODE Simulations Part II</h1>\n"]}, {"cell_type": "markdown", "id": "41345f3a", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_18_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L18.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "fce9b388", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_18_1\">L18.1 Bifurcation Diagrams and Chaotic Motion</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_18_1\">L18.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_18_2\">L18.2 Numerical Precision and Chaotic Dynamics</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_18_2\">L18.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_18_3\">L18.3 Machine Learning the Pendulum Part I</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_18_3\">L18.3 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_18_4\">L18.4 Machine Learning the Pendulum Part II</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_18_4\">L18.4 Exercises</a></td>\n", "    </tr>\n", "</table>"]}, {"cell_type": "code", "execution_count": null, "id": "d59f3ad0", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L18.0-runcell00\n", "\n", "!git init\n", "!git remote add -f origin https://github.com/mitx-8s50/nb_LEARNER/\n", "!git config core.sparseCheckout true\n", "!echo 'data/L18' >> .git/info/sparse-checkout\n", "!git pull origin main\n", "\n", "#NOTE: must create L18 directory on github"]}, {"cell_type": "code", "execution_count": null, "id": "84a48878", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L18.0-runcell01\n", "\n", "#you may need to install this package (it already available in Colab)\n", "#!pip install imageio    #https://imageio.readthedocs.io/en/stable/"]}, {"cell_type": "code", "execution_count": null, "id": "0f3a0154", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L18.0-runcell02\n", "\n", "import imageio                        #https://imageio.readthedocs.io/en/stable/\n", "from PIL import Image                 #https://pillow.readthedocs.io/en/stable/reference/Image.html\n", "\n", "import numpy as np                    #https://numpy.org/doc/stable/\n", "import torch                          #https://pytorch.org/docs/stable/torch.html\n", "import torch.nn as nn                 #https://pytorch.org/docs/stable/nn.html\n", "import matplotlib.pyplot as plt       #https://matplotlib.org/stable/api/pyplot_summary.html#module-matplotlib.pyplot\n", "\n", "from scipy.integrate import odeint    #https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html\n", "from scipy.optimize import minimize   #https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\n", "import csv                            #https://docs.python.org/3/library/csv.html\n", "from matplotlib.patches import Circle #https://matplotlib.org/stable/api/_as_gen/matplotlib.patches.Circle.html\n", "from scipy.integrate import solve_ivp #https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html\n", "from IPython.display import Image     #https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html"]}, {"cell_type": "code", "execution_count": null, "id": "97d0edf8", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L18.0-runcell02\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title"]}, {"cell_type": "markdown", "id": "e198f21b", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_18_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L18.1 Bifurcation Diagrams and Chaotic Motion</h2>  \n", "\n", "| [Top](#section_18_0) | [Previous Section](#section_18_0) | [Exercises](#exercises_18_1) | [Next Section](#section_18_2) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "26787f50", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L18.1-runcell01\n", "\n", "def logistic(r, x):\n", "    return r * x * (1 - x)\n", "\n", "#vary parameters to change density of points\n", "iterations=2000\n", "last = 200\n", "n = 10000\n", "r = np.linspace(2.5, 4.0, n)\n", "x = 1e-5 * np.ones(n)\n", "\n", "fig, ax1 = plt.subplots(1, 1, figsize=(8, 9),sharex=True)\n", "for i in range(iterations):\n", "    x = logistic(r, x)   \n", "    # We compute the partial sum of the\n", "    # Lyapunov exponent.<a name='section_15_2'></a>\n", "    #lyapunov += np.log(abs(r - 2 * r * x))\n", "    # We display the bifurcation diagram.\n", "    if i >= (iterations - last):\n", "        ax1.plot(r, x, ',k', alpha=.25)\n", "ax1.set_xlabel('r')\n", "ax1.set_ylabel('x')\n", "ax1.set_xlim(2.5, 4)\n", "ax1.set_title(\"Bifurcation diagram\")\n"]}, {"cell_type": "code", "execution_count": null, "id": "c189cbbd", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L18.1-runcell02\n", "\n", "def df(t, thetavec, g, l, mup, fp, omega):\n", "    theta, thetadot = thetavec\n", "    return [thetadot, -(g/l) * np.sin(theta) - mup*thetadot + fp*np.cos(omega*t) ]\n", "\n", "g=9.8\n", "l=9.8\n", "thetainit=0.2\n", "mu=0.5\n", "fp=1.2\n", "omega=2./3.\n", "solution = solve_ivp(df, [0., 100], [thetainit, 0.], max_step = 0.1, args=(g,l,mu,fp,omega))\n", "\n", "plt.plot(solution.t, solution.y[0] % (2*np.pi),label=\"int-position\")\n", "plt.plot(solution.t, solution.y[1],label=\"int-velocity\")\n", "plt.xlabel(\"time(s)\")\n", "plt.ylabel(\"position\")\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "id": "02349e43", "metadata": {"scrolled": false, "tags": ["learner", "py", "learner_chopped", "lect_01"]}, "outputs": [], "source": ["#>>>RUN: L18.1-runcell03\n", "\n", "#NOTE: Running this code will take several minutes\n", "#You can ignore the warning messages about redundant colors.\n", "\n", "fp=1.0\n", "thetainit=0.2\n", "mu=0.5\n", "g=9.8\n", "l=9.8\n", "omegad=2./3.\n", "        \n", "for scale in np.arange(1.0,1.2,0.001):\n", "    fptrue=fp*scale\n", "    solution = solve_ivp(df, [0., 1000], [thetainit, 0.], max_step = 0.1, args=(g,l,mu,fptrue,omegad))\n", "    crossings = np.where((solution.y[1][-1000:][:-1]*solution.y[1][-1000:][1:]  <= 0)\n", "                         & (solution.y[1][-1000:][:-1] - solution.y[1][-1000:][1:] > 0)\n", "                        )[0]\n", "    plt.plot(fptrue*np.ones(len(crossings)), (solution.y[0][-1000:][crossings] % (2*np.pi)),',k',c='black',marker=\".\",markersize=2)#, alpha=.25)\n", "\n", "plt.xlabel(\"Driving Force Amplitude (fp)\")\n", "plt.ylabel(\"Phase at Zero-Crossings of Velocity\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "d6ad3f5d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_18_1'></a>     \n", "\n", "| [Top](#section_18_0) | [Restart Section](#section_18_1) | [Next Section](#section_18_2) |\n"]}, {"cell_type": "markdown", "id": "24b1aca7", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 18.1.1</span>\n", "\n", "In a bifurcation diagram, the $x$ axis represents the values of the bifurcation parameter (generically called $r$ in this exercise), while the $y$ axis represents the values  of some property of the system. The diagram shows how the behavior of the system evolves as $r$ changes.\n", "\n", "Features of a bifurcation diagram can include the following:\n", "\n", "**Fixed Points and Stability:** If, for a particular $r$, the system converges to a stable value, it will be represented as a single point in the bifurcation diagram.\n", "\n", "**Periodic Behavior:** The appearance of multiple points or regions in the bifurcation diagram is indicative of periodic behavior in the system. As $r$ varies, the system may transition from stable fixed points to periodic orbits and then to chaos.\n", "\n", "**Bifurcation Points:** Bifurcation points are locations in the diagram where a qualitative change in the system's behavior occurs. This can manifest as a branching or splitting of trajectories.\n", "\n", "**Period-Doubling Cascades:** Successive bifurcation points, leading to the doubling of the period of the system's behavior, are characteristic structures known as period-doubling cascades.\n", "\n", "**Chaos:** Chaotic behavior is often observed in regions of the bifurcation diagram where the system exhibits an extremely sensitive dependence on the initial conditions.\n", "\n", "\n", "Examine the bifurcation diagram below. Which item from the list below best characterizes the feature indicated by the arrow?\n", "\n", "A) Fixed Point\n", "\n", "B) Periodic Behavior\n", "\n", "C) Bifurcation Point\n", "\n", "D) Period-Doubling Cascade\n", "\n", "E) Chaos\n", "\n", "<p align=\"center\">\n", "<img alt=\"Chaotic Phase Space Plot\" src=\"https://raw.githubusercontent.com/mitx-8s50/images/main/L18/chaotic_phase_space.png\" width=\"600\"/>\n", "</p>"]}, {"cell_type": "markdown", "id": "c13cb996", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 18.1.2</span>\n", "\n", "Now, take a more detailed look at the state of the system in the bifurcation diagram for the pendulum example, generated by code cell `L18.1-runcell03`. Make plots of position $\\theta$ on the $x$ axis vs. velocity $\\dot{\\theta}$ on the $y$ axis, for two different values of `fp`, as follows: (1) `fp` corresponding to a stable point, and (2) a `fp` corresponding to a chaotic region. What behavior do you observe in the last 5000 steps of the simulation (after initial variation has subsided)?\n", "\n", "\n", "A) Both plots follow repeating trajectories.\\\n", "B) One plot repeats itself, while the other fills a large fraction of the full phase space.\\\n", "C) Both plots fill a large fraction of the full phase space.\n"]}, {"cell_type": "code", "execution_count": null, "id": "22d7b3f7", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L18.1.2\n", "\n", "#plot 1: stable point\n", "scale_stable = #YOUR CODE HERE (choose value based on output of L18.1-runcell03)\n", "\n", "solution = solve_ivp(df, [0., 100000*0.01], [thetainit, 0.], max_step = 0.1, args=(g,l,mu,fp*scale_stable,omegad))\n", "plt.plot((solution.y[0,-5000:] + np.pi) % (2*np.pi), solution.y[1,-5000:] ,label=\"int-position\")\n", "plt.xlabel(\"position\")\n", "plt.ylabel(\"velocity\")\n", "plt.title('Stable Dynamics')\n", "plt.show()\n", "\n", "#plot 2: chaotic region\n", "scale_chaotic = #YOUR CODE HERE (choose value based on output of L18.1-runcell03)\n", "\n", "solution = solve_ivp(df, [0., 100000*0.01], [thetainit, 0.], max_step = 0.1, args=(g,l,mu,fp*scale_chaotic,omegad))\n", "plt.plot((solution.y[0,-5000:] + np.pi) % (2*np.pi), solution.y[1,-5000:] ,label=\"int-position\")\n", "plt.xlabel(\"position\")\n", "plt.ylabel(\"velocity\")\n", "plt.title('Chaotic Dynamics')\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "e29cebe2", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_18_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L18.2 Numerical Precision and Chaotic Dynamics</h2>  \n", "\n", "| [Top](#section_18_0) | [Previous Section](#section_18_1) | [Exercises](#exercises_18_2) | [Next Section](#section_18_3) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "5c51aff9", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_02"]}, "outputs": [], "source": ["#>>>RUN: L18.2-runcell01\n", "\n", "def store(theta,thetapos,time,timepos):\n", "    thetapos = np.vstack((thetapos,theta))\n", "    timepos  = np.vstack((timepos,time))\n", "    return timepos,thetapos\n", "\n", "def step(theta,t,dt,g,l,mu,f,omegad):\n", "    theta[0] += theta[1] * dt \n", "    #theta[1] += (g/l)*(-1)*theta[0]*dt\n", "    #print(((g/l)*(-1)*np.sin(theta[0])-mu*theta[1]+f*np.sin(omegad*t))*dt)\n", "    theta[1] += ((g/l)*(-1)*np.sin(theta[0])-mu*theta[1]+f*np.sin(omegad*t))*dt\n", "   \n", "def loop(nsteps=1000,dt=0.01,g=9.8,l=9.8,mu=0.5,f=1.0,omegad=omegad):\n", "    timepos  = np.zeros(1)\n", "    thetapos = np.zeros((1,2));\n", "    time     = 0\n", "    theta    = np.zeros(2)\n", "    theta[0] = thetainit #initial conditions\n", "    theta[1] = 0.0\n", "    theta[1] += ((g/l)*(-1)*np.sin(theta[0])-mu*theta[1]+f*np.sin(omegad*time))*dt*0.5\n", "    timepos,thetapos=store(theta,thetapos,time,timepos)\n", "    for timestep in range(nsteps):\n", "        step(theta,time,dt,g,l,mu,f,omegad)\n", "        time += dt\n", "        timepos,thetapos=store(theta,thetapos,time,timepos)\n", "    return timepos,thetapos\n", "\n", "time,thetaout=loop(100000,dt=0.01,g=g,l=l,mu=mu,f=fp*1.05,omegad=omegad)\n", "print(thetaout)\n", "solution = solve_ivp(df, [0., 100000*0.01], [thetainit, 0.], max_step = 0.1, args=(g,l,mu,fp*1.05,omegad))\n", "plt.plot((solution.y[0] + np.pi) % (2*np.pi), solution.y[1] ,label=\"IVP\")\n", "plt.plot((thetaout[:,0] + np.pi) % (2*np.pi), thetaout[:,1] ,label=\"LEAP-FROG\")\n", "plt.xlabel(\"position\")\n", "plt.ylabel(\"velocity\")\n", "plt.legend()\n", "plt.show()\n", "\n", "time,thetaout=loop(100000,dt=0.01,g=g,l=l,mu=mu,f=fp*1.12,omegad=omegad)\n", "print(thetaout)\n", "solution = solve_ivp(df, [0., 100000*0.01], [thetainit, 0.], max_step = 0.1, args=(g,l,mu,fp*1.12,omegad))\n", "plt.plot((solution.y[0] + np.pi) % (2*np.pi), solution.y[1] ,label=\"IVP\")\n", "plt.plot((thetaout[:,0] + np.pi) % (2*np.pi), thetaout[:,1] ,label=\"LEAP-FROG\")\n", "plt.xlabel(\"position\")\n", "plt.ylabel(\"velocity\")\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "id": "858dcf99", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_18_2'></a>     \n", "\n", "| [Top](#section_18_0) | [Restart Section](#section_18_2) | [Next Section](#section_18_3) |\n"]}, {"cell_type": "markdown", "id": "99a02ccb", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 18.2.1</span>\n", "\n", "Make a bifurcation diagram that is similar to the one produced by `L18.1-runcell03`, now using the Leap-Frog integrator (this will take a long time). Are the regions of stability, bifurcation, and choas the same? Choose an answer below:\n", "\n", "A) No, the regions are entirely different and not at all similar.\n", "\n", "B) Yes, the regions are identical.\n", "\n", "C) The features are similar, but not identical.\n"]}, {"cell_type": "markdown", "id": "1aa2b39d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 18.2.2</span>\n", "\n", "The purpose of a Poincar\u00e9 section is to simplify the analysis of complex, high-dimensional systems by examining their behavior in a lower-dimensional space that is meaningful.\n", "\n", "From the following options, select ALL answers which are valid examples of Poincar\u00e9 sections:\n", "\n", "A) A plane perpendicular to the trajectory of a swinging pendulum, intersecting the trajectory at each oscillation.\n", "\n", "B) A random slice through the three-dimensional phase space of a chaotic system, capturing points at arbitrary locations.\n", "\n", "C) A sphere enclosing the orbit of a satellite around a planet, capturing points as the satellite completes each orbit.\n", "\n", "D) A plane tangential to the trajectory of a spinning top, capturing points as the top precesses.\n"]}, {"cell_type": "markdown", "id": "1a056579", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_18_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L18.3 Machine Learning the Pendulum Part I</h2>  \n", "\n", "| [Top](#section_18_0) | [Previous Section](#section_18_2) | [Exercises](#exercises_18_3) | [Next Section](#section_18_4) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "173a4946", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L18.3-runcell01\n", "\n", "def oscillator(d, w0, x):\n", "    w = np.sqrt(w0**2-d**2)\n", "    phi = np.arctan(-d/w)\n", "    A = 1/(np.cos(phi))\n", "    cos = torch.cos(phi+w*x)\n", "    sin = torch.sin(phi+w*x)\n", "    exp = torch.exp(-d*x)\n", "    y  = exp*A*cos\n", "    return y\n", "\n", "class MLP(nn.Module):    \n", "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN):\n", "        super().__init__()\n", "        activation = nn.Tanh\n", "        self.input = nn.Sequential(\n", "                        nn.Linear(N_INPUT, N_HIDDEN),\n", "                        activation()\n", "                      )\n", "        self.hidden = nn.Sequential(\n", "                    nn.Linear(N_HIDDEN, N_HIDDEN),\n", "                    activation(),\n", "                    nn.Linear(N_HIDDEN, N_HIDDEN),\n", "                    activation(),\n", "                    nn.Linear(N_HIDDEN, N_HIDDEN),\n", "                    activation(),        \n", "                    )\n", "\n", "        self.output = nn.Linear(N_HIDDEN, N_OUTPUT)\n", "        #self.fcs = nn.Sequential(*[nn.Linear(N_INPUT, N_HIDDEN),activation()])\n", "        #self.fch = nn.Sequential(*[nn.Sequential(*[nn.Linear(N_HIDDEN, N_HIDDEN),activation()]) for _ in range(N_LAYERS-1)])\n", "        #self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n", "        \n", "    def forward(self, x):\n", "        x = self.input(x)\n", "        x = self.hidden(x)\n", "        x = self.output(x)\n", "        return x\n", "    \n"]}, {"cell_type": "code", "execution_count": null, "id": "52868866", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L18.3-runcell02\n", "\n", "d, w0 = 2, 20\n", "\n", "# get the analytical solution over the full domain\n", "x = torch.linspace(0,1,500).view(-1,1)\n", "y = oscillator(d, w0, x).view(-1,1)\n", "\n", "# slice out a small number of points from the LHS of the domain\n", "x_data = x[0:200:20] # take just one event every 20th from 0 to 200\n", "y_data = y[0:200:20]\n", "print(x_data.shape, y_data.shape)\n", "\n", "plt.figure()\n", "plt.plot(x, y, label=\"Exact solution\")\n", "plt.scatter(x_data, y_data, color=\"tab:orange\", label=\"Training data\")\n", "plt.xlabel('time')\n", "plt.ylabel('Amplitude')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "c22aa23a", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_03"]}, "outputs": [], "source": ["#>>>RUN: L18.3-runcell03\n", "\n", "def plot_result(x,y,x_data,y_data,yh,fig,ax,images=[],xp=None):\n", "    plt.cla()\n", "    plt.plot(x,y, color=\"grey\", linewidth=2, alpha=0.8, label=\"Exact solution\")\n", "    plt.plot(x,yh, color=\"tab:blue\", linewidth=4, alpha=0.8, label=\"Neural network prediction\")\n", "    plt.scatter(x_data, y_data[:,0], s=60, color=\"tab:orange\", alpha=0.4, label='Training data')\n", "    if xp is not None:\n", "        plt.scatter(xp, -0*torch.ones_like(xp), s=60, color=\"tab:green\", alpha=0.4, \n", "                    label='Physics loss training locations')\n", "    l = plt.legend(loc=(0.865,0.60), frameon=False, fontsize=\"large\")\n", "    plt.setp(l.get_texts(), color=\"k\")\n", "    plt.xlim(-0.05, 1.05)\n", "    plt.ylim(-1.1, 1.1)\n", "    plt.text(0.865,0.7,\"Training step: %i\"%(i+1),fontsize=\"xx-large\",color=\"k\")\n", "    plt.axis(\"off\")\n", "    fig.canvas.draw() \n", "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n", "    image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n", "    images.append(image)\n", "\n", "    \n", "# train standard neural network to fit training data\n", "torch.manual_seed(123)\n", "model = MLP(1,1,32)\n", "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n", "images = []\n", "fig, ax = plt.subplots(figsize=(10,5))\n", "y_data=torch.hstack((y_data,torch.ones(10,1)))\n", "for i in range(1000):\n", "    optimizer.zero_grad()\n", "    yh = model(x_data)\n", "    loss = torch.mean((yh[:,0:1]-y_data[:,0:1])**2)# use mean squared error\n", "    loss.backward()\n", "    optimizer.step()\n", "    \n", "    # plot the result as training progresses\n", "    if (i+1) % 100 == 0: \n", "        print(loss.item())\n", "        yh = model(x).detach()\n", "        plot_result(x,y,x_data,y_data,yh,fig,ax,images)\n", "\n", "imageio.mimsave('data/L18/training.gif', images, fps=10, loop=0)\n", "Image(open('data/L18/training.gif','rb').read())\n", "#NOTE: gifs can be opened in COLAB by double-clicking file in related `data` directory"]}, {"cell_type": "markdown", "id": "c4faf19e", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_18_3'></a>     \n", "\n", "| [Top](#section_18_0) | [Restart Section](#section_18_3) | [Next Section](#section_18_4) |\n"]}, {"cell_type": "markdown", "id": "361a4fe2", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 18.3.1</span>\n", "\n", "Add 5 data points to the data set, corresponding to evenly spaced points sampled from the LAST 100 points, and re-run the neural network above. What is the last loss value that is printed? Report your new answer as a number with precision `1e-5`.\n", "\n", "Does the NN do a better job at fitting when using additional data from the end of the dataset?"]}, {"cell_type": "code", "execution_count": null, "id": "323b6911", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L18.3.1\n", "\n", "#combine the original data set and last 5 evenly-spaced points\n", "x_data = torch.vstack(#YOUR CODE HERE)\n", "y_data = torch.vstack(#YOUR CODE HERE)\n", "\n", "    \n", "#RUN THE NN AGAIN\n", "#YOUR CODE HERE\n", "    \n", "\n", "imageio.mimsave('data/L18/training2.gif', images, fps=10, loop=0)\n", "Image(open('data/L18/training2.gif','rb').read())\n", "#NOTE: gifs can be opened in COLAB by double-clicking file in related `data` directory\n"]}, {"cell_type": "markdown", "id": "18254bec", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_18_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L18.4 Machine Learning the Pendulum Part II</h2>  \n", "\n", "| [Top](#section_18_0) | [Previous Section](#section_18_3) | [Exercises](#exercises_18_4) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "4fbf76a0", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_04"]}, "outputs": [], "source": ["#>>>RUN: L18.4-runcell01\n", "\n", "#First let's apply the model\n", "x_physics = torch.linspace(0,1,30).view(-1,1).requires_grad_(True)# sample locations over the problem domain\n", "yhp = model(x_physics)\n", "dx  = torch.autograd.grad(yhp, x_physics, torch.ones_like(yhp), create_graph=True)[0]# computes dy/dx\n", "dx2 = torch.autograd.grad(dx,  x_physics, torch.ones_like(dx),  create_graph=True)[0]# computes d^2y/dx^2\n", "dx*=0.1\n", "dx2*=0.01\n", "plt.plot(x,y, color=\"grey\", linewidth=2, alpha=0.8, label=\"Exact solution\")\n", "plt.plot(x,yh, color=\"tab:blue\", linewidth=4, alpha=0.8, label=\"Neural network prediction\")\n", "plt.scatter(x_physics.detach(), yhp.detach().numpy(), s=60, color=\"tab:orange\", alpha=0.4, label='Training data')\n", "plt.scatter(x_physics.detach(), dx.detach(), s=60, color=\"tab:green\", alpha=0.4, label='0.1(dx/dt)')\n", "plt.scatter(x_physics.detach(), dx2.detach(), s=60, color=\"tab:cyan\", alpha=0.4, label='0.01(d$^{2}$x/dt$^{2}$)')\n", "plt.scatter(x_physics.detach(), 0.1*dx2.detach()/yhp.detach(), s=60, color=\"blue\", alpha=0.4, label='0.01(d$^{2}$x/dt$^{2}$)/x(t)')\n", "plt.ylim(-3,3)\n", "plt.legend()\n", "plt.xlabel(\"time(s)\")\n", "plt.ylabel(\"x(t)\")\n", "plt.show()\n", "\n", "#note, your results may look slightly different than the related video,\n", "#if you just retrained the NN in Exercise 18.3.1"]}, {"cell_type": "code", "execution_count": null, "id": "8116e720", "metadata": {"scrolled": false, "tags": ["learner", "py", "learner_chopped", "lect_04"]}, "outputs": [], "source": ["#>>>RUN: L18.4-runcell02\n", "\n", "#x_physics = torch.linspace(0,1,30).view(-1,1).requires_grad_(True)# sample locations over the problem domain\n", "mu, k = 2*d, w0**2\n", "model = MLP(1,1,32)\n", "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n", "\n", "#Back to the origin data arrays that we were using before\n", "x_data = x[0:200:20] # take just one event every 20th from 0 to 200\n", "y_data = y[0:200:20]\n", "\n", "torch.manual_seed(123)\n", "images = []\n", "fig, ax = plt.subplots(figsize=(10,5))\n", "for i in range(20000):\n", "    optimizer.zero_grad()\n", "    \n", "    # compute the \"data loss\"\n", "    yh = model(x_data)\n", "    loss1 = torch.mean((yh[:,0:1]-y_data[:,0:1])**2)# use mean squared error\n", "\n", "    # compute the \"physics loss\"\n", "    yhp = model(x_physics)\n", "    dx  = torch.autograd.grad(yhp, x_physics, torch.ones_like(yhp), create_graph=True)[0]# computes dy/dx\n", "    dx2 = torch.autograd.grad(dx,  x_physics, torch.ones_like(dx),  create_graph=True)[0]# computes d^2y/dx^2\n", "    physics = dx2 +  mu*dx +  k*yhp# computes the residual of the 1D harmonic oscillator differential equation\n", "    loss2 = (1e-4)*torch.mean(physics**2)  #Note the multiplicative factor!\n", "    \n", "    # backpropagate joint loss\n", "    loss = loss1 + loss2# add two loss terms together\n", "    loss.backward()\n", "    optimizer.step()\n", "    \n", "    \n", "    # plot the result as training progresses\n", "    if (i+1) % 100 == 0: \n", "        \n", "        yh = model(x).detach()\n", "        xp = x_physics.detach()\n", "\n", "        print(loss.item())\n", "        yh = model(x).detach()\n", "        plot_result(x,y,x_data,y_data,yh,fig,ax,images)\n", "\n", "from IPython.display import Image\n", "a=imageio.mimsave('data/L18/training.gif', images, fps=10, loop=0)\n", "Image(open('data/L18/training.gif','rb').read())\n", "#NOTE: gifs can be opened in COLAB by double-clicking file in related `data` directory"]}, {"cell_type": "code", "execution_count": null, "id": "c4ca9fe6", "metadata": {"scrolled": false, "tags": ["learner", "py", "learner_chopped", "lect_04"]}, "outputs": [], "source": ["#>>>RUN: L18.4-runcell03\n", "\n", "#x_physics = torch.linspace(0,1,30).view(-1,1).requires_grad_(True)# sample locations over the problem domain\n", "mu, k = 2*d, w0**2\n", "model1 = MLP(1,1,32)\n", "model2 = MLP(1,2,1)\n", "#model2.Train = False\n", "\n", "optimizer1 = torch.optim.Adam(model1.parameters(),lr=1e-4)\n", "optimizer2 = torch.optim.Adam(model2.parameters(),lr=1e-2)\n", "\n", "torch.manual_seed(123)\n", "images = []\n", "fig, ax = plt.subplots(figsize=(10,5))\n", "for i in range(50000):\n", "    optimizer1.zero_grad()\n", "    optimizer2.zero_grad()\n", "    \n", "    # compute the \"data loss\"\n", "    yh = model1(x_data)\n", "    loss1 = torch.mean((yh[:,0:1]-y_data[:,0:1])**2)# use mean squared error\n", "\n", "    # compute the \"physics loss\"\n", "    yhp   = model1(x_physics)\n", "    decay = model2(x_physics)\n", "    dx  = torch.autograd.grad(yhp, x_physics, torch.ones_like(yhp), create_graph=True)[0]# computes dy/dx\n", "    dx2 = torch.autograd.grad(dx,  x_physics, torch.ones_like(dx),  create_graph=True)[0]# computes d^2y/dx^2\n", "    physics = dx2 +  torch.mean(decay[:,0:1])*dx +  torch.mean(decay[:,1:2])*yhp# computes the residual of the 1D harmonic oscillator differential equation\n", "    loss2 = (1e-4)*torch.mean(physics**2)\n", "    \n", "    # backpropagate joint loss\n", "    loss = loss1 + loss2# add two loss terms together\n", "    loss.backward()\n", "    optimizer1.step()\n", "    optimizer2.step()\n", "    \n", "    \n", "    # plot the result as training progresses\n", "    if (i+1) % 100 == 0: \n", "        \n", "        yh = model1(x).detach()\n", "        xp = x_physics.detach()\n", "\n", "        print(loss.item())\n", "        yh = model1(x).detach()\n", "        plot_result(x,y,x_data,y_data,yh,fig,ax,images)\n", "\n", "from IPython.display import Image\n", "a=imageio.mimsave('data/L18/training.gif', images, fps=10, loop=0)\n", "Image(open('data/L18/training.gif','rb').read())\n", "#NOTE: gifs can be opened in COLAB by double-clicking file in related `data` directory"]}, {"cell_type": "code", "execution_count": null, "id": "d48b4090", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_04"]}, "outputs": [], "source": ["#>>>RUN: L18.4-runcell04\n", "\n", "decays=model2(x_physics)\n", "print(\"NN Mu:\",decays[0][0].detach().numpy(),\"Actual:\",mu,\"NN k: \",decays[0][1].detach().numpy(),\"Actual:\",k)"]}, {"cell_type": "markdown", "id": "d18eaa9c", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_18_4'></a>     \n", "\n", "| [Top](#section_18_0) | [Restart Section](#section_18_4) |\n"]}, {"cell_type": "markdown", "id": "99c8cb42", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 18.4.1</span>\n", "\n", "Again, add 5 data points to the data set, corresponding to evenly spaced points sampled from the LAST 100 points, and re-run the neural network above. How does this change the final value of the decay parameter? Report your new result for $\\mu$, as a number with precision `1e-3`.\n", "\n", "Before running your solution code, think a bit about what you expect will happen."]}, {"cell_type": "code", "execution_count": null, "id": "bf1be391", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L18.4.1\n", "\n", "#combine the original data set and last 5 evenly-spaced points\n", "x_data = torch.vstack(#YOUR CODE HERE)\n", "y_data = torch.vstack(#YOUR CODE HERE)\n", "\n", "    \n", "#RUN THE NN AGAIN\n", "#YOUR CODE HERE\n", "    \n", "#print the parameters  \n", "decays=model2(x_physics)\n", "print(\"NN Mu:\",decays[0][0].detach().numpy(),\"Actual:\",mu,\"NN k: \",decays[0][1].detach().numpy(),\"Actual:\",k)"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}