{"cells": [{"cell_type": "markdown", "id": "4930b1e3", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 25: Anomaly Detection</h1>"]}, {"cell_type": "markdown", "id": "9f23fcdd", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_25_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L25.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "22ed1587", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_25_1\">25.1 The Gaia Experiment</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_25_1\">L25.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_25_2\">25.2 Building Projections with Gaia</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_25_2\">L25.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_25_3\">25.3 Anomaly Detection with Gaia</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_25_3\">L25.3 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_25_4\">25.4 Anomaly Detection with Lots of Gaia Data</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_25_4\">L25.4 Exercises</a></td>\n", "    </tr>\n", "</table>"]}, {"cell_type": "code", "execution_count": null, "id": "b45f7114", "metadata": {"tags": ["py", "leaner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.0-runcell00\n", "\n", "!git init\n", "!git remote add -f origin https://github.com/mitx-8s50/nb_LEARNER/\n", "!git config core.sparseCheckout true\n", "!echo 'data/L25' >> .git/info/sparse-checkout\n", "!git pull origin main\n"]}, {"cell_type": "code", "execution_count": null, "id": "40dfa881", "metadata": {"tags": ["py", "leaner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.0-runcell01\n", "\n", "!pip install astropy==6.0.0\n", "!pip install astroquery==0.4.7\n", "!pip install gala==1.8.1\n"]}, {"cell_type": "code", "execution_count": null, "id": "f1a51921", "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.0-runcell02\n", "\n", "# astropy imports\n", "import astropy.coordinates as coord\n", "from astropy.table import QTable\n", "import astropy.units as u\n", "from astroquery.gaia import Gaia\n", "\n", "# Third-party imports\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "%matplotlib inline\n", "\n", "# gala imports\n", "import gala.coordinates as gc\n", "import gala.dynamics as gd\n", "import gala.potential as gp\n", "from gala.units import galactic\n", "\n", "#ML imports\n", "import torch\n", "import torch.nn as nn\n", "from torch.utils.data import Dataset\n", "from torch.autograd import Variable\n"]}, {"cell_type": "code", "execution_count": null, "id": "c8b9d625", "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.0-runcell03\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title"]}, {"cell_type": "markdown", "id": "bcb48e25", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_25_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\"> L25.1 The Gaia Experiment </h2>  \n", "\n", "| [Top](#section_25_0) | [Previous Section](#section_25_0) | [Exercises](#exercises_25_1) | [Next Section](#section_25_2) |"]}, {"cell_type": "code", "execution_count": null, "id": "8fe9cb80", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.1-runcell01\n", "\n", "query_text = '''SELECT TOP 4096 ra, dec, parallax, pmra, pmdec, radial_velocity,\n", "phot_g_mean_mag, phot_bp_mean_mag, phot_rp_mean_mag\n", "FROM gaiadr3.gaia_source\n", "WHERE parallax_over_error > 10 AND\n", "    parallax > 10 AND\n", "    radial_velocity IS NOT null\n", "ORDER BY random_index\n", "'''\n", "\n", "job = Gaia.launch_job(query_text)\n", "gaia_data = job.get_results()\n", "gaia_data.write('data/L25/gaia_data1.fits',overwrite=True)\n", "\n", "#Note, if you return to this section after closing the kernel,\n", "#you can load the data again using the following code\n", "gaia_data = QTable.read('data/L25/gaia_data1.fits')\n", "\n", "\n", "print(\"Total Events:\",len(gaia_data))\n", "print()\n", "print(gaia_data[:4])\n", "\n", "#Note, the columns in our dataset are defined by our query above.\n", "#To print one column, use the command gaia_data['column_name'], e.g.: gaia_data['parallax']"]}, {"cell_type": "code", "execution_count": null, "id": "f442ac54", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.1-runcell02\n", "\n", "dist = coord.Distance(parallax=u.Quantity(gaia_data['parallax']))\n", "print(\"Min:\",dist.min(), \"Max:\",dist.max())\n", "print(dist[0],1e3/gaia_data['parallax'][0])\n", "\n", "plt.hist(dist)\n", "plt.xlabel(\"distance (pcs)\")\n", "plt.ylabel(\"N\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "b9b1e98b", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.1-runcell03\n", "\n", "c = coord.SkyCoord(ra=gaia_data['ra'], dec=gaia_data['dec'],distance=dist,\n", "                   pm_ra_cosdec=gaia_data['pmra'], pm_dec=gaia_data['pmdec'],\n", "                   radial_velocity=gaia_data['radial_velocity'])\n", "\n", "print(c[:4],'\\n')\n", "print()\n", "\n", "#Now we can translate it to galactic coordinates\n", "print(c.galactic[:4])\n", "coord.Galactocentric()"]}, {"cell_type": "code", "execution_count": null, "id": "ea485305", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.1-runcell04\n", "\n", "galcen = c.transform_to(coord.Galactocentric(z_sun=0*u.pc, galcen_distance=8.1*u.kpc))\n", "print(galcen[:4],'\\n')\n", "plt.hist(galcen.z.value, bins=np.linspace(-110, 110, 32),alpha=0.5,label='z')\n", "#plt.hist(galcen.x.value, bins=np.linspace(-110, 110, 32),alpha=0.5)\n", "plt.hist(galcen.y.value, bins=np.linspace(-110, 110, 32),alpha=0.5,label='y')\n", "plt.xlabel('Corrdinate position (about Galactic Plane) [{0:latex_inline}]'.format(galcen.z.unit));\n", "plt.legend()\n", "plt.show()\n", "\n", "plt.hist(galcen.x.value, alpha=0.5)\n", "plt.xlabel('X-position (nearby stars) [{0:latex_inline}]'.format(galcen.x.unit))\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "id": "6cf57210", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.1-runcell05\n", "\n", "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n", "ax.plot(galcen.v_x.value, galcen.v_y.value,marker='.', linestyle='none', alpha=0.5)\n", "ax.set_xlim(-125, 125)\n", "ax.set_ylim(200-125, 200+125)\n", "ax.set_xlabel('vx [{0:latex_inline}]'.format(u.km/u.s))\n", "ax.set_ylabel('vy [{0:latex_inline}]'.format(u.km/u.s))\n", "plt.show()\n", "\n", "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n", "plt.plot(galcen.v_x.value, galcen.v_z.value,marker='.', linestyle='none', alpha=0.5)\n", "plt.xlabel('vx [{0:latex_inline}]'.format(u.km/u.s))\n", "plt.ylabel('vz [{0:latex_inline}]'.format(u.km/u.s))\n", "plt.xlim(-125, 125)\n", "plt.ylim(-125, 125)\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "id": "421aa070", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.1-runcell06\n", "\n", "M_G = gaia_data['phot_g_mean_mag'] - dist.distmod #corrected Star Magnitude (general-distance mod)\n", "BP_RP = gaia_data['phot_bp_mean_mag'] - gaia_data['phot_rp_mean_mag'] #Blue filter - read filter\n", "\n", "plt.plot(BP_RP.value, M_G.value, marker='.', linestyle='none', alpha=0.3)\n", "\n", "plt.xlim(0, 3)\n", "plt.ylim(11, 1)\n", "\n", "#expand range\n", "#plt.xlim(0, 3.75)\n", "#plt.ylim(13.5, 0)\n", "\n", "plt.xlabel('$G_{BP}-G_{RP}$')\n", "plt.ylabel('$M_{G}$')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "54ed5279", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.1-runcell07\n", "\n", "np.seterr(invalid=\"ignore\")\n", "#Red+0.7 > Blue > Red+0.5 and 2 < Star magnitude < 3.75\n", "hi_mass_mask = ((BP_RP > 0.5*u.mag) & (BP_RP < 0.7*u.mag) & (M_G > 2*u.mag) & (M_G < 3.75*u.mag))\n", "#                &                 (np.abs(galcen.v_y - 220*u.km/u.s) < 50*u.km/u.s))\n", "\n", "#Red+2.4 > Blue > Red+2 and 8.2 < Star magnitude < 9.7\n", "lo_mass_mask = ((BP_RP > 2*u.mag) & (BP_RP < 2.4*u.mag) & (M_G > 8.2*u.mag) & (M_G < 9.7*u.mag))\n", "#                &                (np.abs(galcen.v_y - 220*u.km/u.s) < 50*u.km/u.s))\n", "\n", "hi_mass_color = 'tab:purple'\n", "lo_mass_color = 'tab:red'\n", "hi_mass_label = 'high mass'\n", "lo_mass_label = 'low mass'\n", "milky_way = gp.MilkyWayPotential()\n", "milky_way\n", "\n", "plt.plot(BP_RP.value, M_G.value, marker='.', linestyle='none', alpha=0.1)\n", "\n", "for mask, color, label in zip([lo_mass_mask, hi_mass_mask],[lo_mass_color, hi_mass_color], [lo_mass_label, hi_mass_label]):\n", "    plt.plot(BP_RP[mask].value, M_G[mask].value, marker='.', linestyle='none', \n", "            alpha=0.5, color=color, label=label)\n", "\n", "plt.xlim(0, 3)\n", "plt.ylim(11, 1)\n", "\n", "plt.xlabel('$G_{BP}-G_{RP}$')\n", "plt.ylabel('$M_{G}$')\n", "plt.legend()\n", "plt.show()\n", "     \n", "     "]}, {"cell_type": "code", "execution_count": null, "id": "3631000d", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.1-runcell08\n", "\n", "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n", "\n", "ax.plot(galcen[1==1].x.value, galcen[1==1].y.value,marker='.', linestyle='none', alpha=0.02,color='blue')\n", "ax.plot(galcen[lo_mass_mask].x.value, galcen[lo_mass_mask].y.value,marker='.', linestyle='none', alpha=0.5,color=lo_mass_color, label=lo_mass_label)\n", "ax.plot(galcen[hi_mass_mask].x.value, galcen[hi_mass_mask].y.value,marker='.', linestyle='none', alpha=0.5,color=hi_mass_color, label=hi_mass_label)\n", "ax.set_xlabel('x [{0:latex_inline}]'.format(galcen.x.unit));\n", "ax.set_ylabel('y [{0:latex_inline}]'.format(galcen.y.unit));\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "3bc0efe4", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.1-runcell09\n", "\n", "r_ce = np.sqrt(galcen[1==1]        .y.value**2 + galcen[1==1]        .z.value**2)\n", "r_lo = np.sqrt(galcen[lo_mass_mask].y.value**2 + galcen[lo_mass_mask].z.value**2)\n", "r_hi = np.sqrt(galcen[hi_mass_mask].y.value**2 + galcen[hi_mass_mask].z.value**2)\n", "\n", "hist_ce, bin_edges = np.histogram(r_ce,bins=10, density=True)\n", "hist_lo, bin_edges = np.histogram(r_lo, bins=bin_edges, density=True)\n", "hist_hi, bin_edges = np.histogram(r_hi, bins=bin_edges, density=True)\n", "bin_center = 0.5*(bin_edges[:-1] + bin_edges[1:])\n", "sc=1./(len(galcen))\n", "sl=1./(len(galcen[lo_mass_mask]))\n", "sh=1./(len(galcen[hi_mass_mask]))\n", "plt.errorbar(bin_center,hist_ce,yerr=sc*hist_ce**0.5,alpha=0.5,drawstyle=\"steps-mid\",marker='.',color='blue',label='all')\n", "plt.errorbar(bin_center,hist_lo,yerr=sl*hist_lo**0.5,alpha=0.5,drawstyle=\"steps-mid\",marker='.',color=lo_mass_color,label=lo_mass_label)\n", "plt.errorbar(bin_center,hist_hi,yerr=sh*hist_hi**0.5,alpha=0.5,drawstyle=\"steps-mid\",marker='.',color=hi_mass_color,label=hi_mass_label)\n", "plt.xlabel('y[pc]')\n", "plt.legend()\n", "plt.show()\n", "\n", "\n", "vr_ce = np.sqrt(galcen[1==1]        .v_y.value**2 + galcen[1==1]        .v_x.value**2)\n", "vr_lo = np.sqrt(galcen[lo_mass_mask].v_y.value**2 + galcen[lo_mass_mask].v_x.value**2)\n", "vr_hi = np.sqrt(galcen[hi_mass_mask].v_y.value**2 + galcen[hi_mass_mask].v_x.value**2)\n", "\n", "hist_ce, bin_edges = np.histogram(vr_ce,bins=20, density=True)\n", "hist_lo, bin_edges = np.histogram(vr_lo, bins=bin_edges, density=True)\n", "hist_hi, bin_edges = np.histogram(vr_hi, bins=bin_edges, density=True)\n", "bin_center = 0.5*(bin_edges[:-1] + bin_edges[1:])\n", "sc=1./(len(galcen))\n", "sl=1./(len(galcen[lo_mass_mask]))\n", "sh=1./(len(galcen[hi_mass_mask]))\n", "plt.errorbar(bin_center,hist_ce,yerr=sc*hist_ce**0.5,alpha=0.5,drawstyle=\"steps-mid\",marker='.',color='blue',label='all')\n", "plt.errorbar(bin_center,hist_lo,yerr=sl*hist_lo**0.5,alpha=0.5,drawstyle=\"steps-mid\",marker='.',color=lo_mass_color,label=lo_mass_label)\n", "plt.errorbar(bin_center,hist_hi,yerr=sh*hist_hi**0.5,alpha=0.5,drawstyle=\"steps-mid\",marker='.',color=hi_mass_color,label=hi_mass_label)\n", "plt.xlabel('v$_{r}$[km/s]')\n", "plt.legend()\n", "plt.show()\n", "\n", "\n", "vz_ce = galcen[1==1]        .v_z.value\n", "vz_lo = galcen[lo_mass_mask].v_z.value\n", "vz_hi = galcen[hi_mass_mask].v_z.value\n", "\n", "hist_ce, bin_edges = np.histogram(vz_ce,bins=20, density=True)\n", "hist_lo, bin_edges = np.histogram(vz_lo, bins=bin_edges, density=True)\n", "hist_hi, bin_edges = np.histogram(vz_hi, bins=bin_edges, density=True)\n", "bin_center = 0.5*(bin_edges[:-1] + bin_edges[1:])\n", "sc=1./(len(galcen))\n", "sl=1./(len(galcen[lo_mass_mask]))\n", "sh=1./(len(galcen[hi_mass_mask]))\n", "plt.errorbar(bin_center,hist_ce,yerr=sc*hist_ce**0.5,alpha=0.5,drawstyle=\"steps-mid\",marker='.',color='blue',label='all')\n", "plt.errorbar(bin_center,hist_lo,yerr=sl*hist_lo**0.5,alpha=0.5,drawstyle=\"steps-mid\",marker='.',color=lo_mass_color,label=lo_mass_label)\n", "plt.errorbar(bin_center,hist_hi,yerr=sh*hist_hi**0.5,alpha=0.5,drawstyle=\"steps-mid\",marker='.',color=hi_mass_color,label=hi_mass_label)\n", "plt.xlabel('v$_{z}$[km/s]')\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "45901919", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_25_1'></a>     \n", "\n", "| [Top](#section_25_0) | [Restart Section](#section_25_1) | [Next Section](#section_25_2) |\n"]}, {"cell_type": "markdown", "id": "0f6ab667", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 25.1.1</span>\n", "\n", "We've compared the distributions of high mass stars and low mass stars. Now, partition the intermediate mass stars and compare their distributions.\n", "\n", "Specifically, define two group of stars, `intermed1`, with a `BP_RP` color in the range `[1,1.5]` and a magnitude in the range `[5,7.5]`, and `intermed2`, with a `BP_RP` color in the range `[1.5,2]` and a magnitude in the range `[6.5,8.5]`.\n", "\n", "Hint: It might be convenient to wrap some of the cells above into a function, which takes the masks, colors, and labels as inputs.\n", "\n", "\n", "What do you see?\n", "\n", "A) There appears to be no difference in the distributions.\n", "\n", "B) These distributions are now clearly different.\n", "\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "3ce153ce", "metadata": {"tags": ["learner_chopped", "py", "draft"]}, "outputs": [], "source": ["#>>>EXERCISE: L25.1.1\n", "\n", "np.seterr(invalid=\"ignore\")\n", "\n", "#DEFINE MASKS\n", "intermed1_mask = #YOUR CODE HERE\n", "intermed2_mask = #YOUR CODE HERE\n", "\n", "intermed1_color = 'tab:green'\n", "intermed2_color = 'tab:orange'\n", "intermed1_label = 'intermed1'\n", "intermed2_label = 'intermed2'\n", "\n", "\n", "#YOUR CODE HERE (APPLY MASKS, MAKE PLOTS)\n", "\n", "     "]}, {"cell_type": "markdown", "id": "0b10231d", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 25.1.2</span>\n", "\n", "What if we consider some of the other variables? Select objects with extreme radial velocity, and see how they look in the HR diagram.  Specifically, select events with radial velocity < 100 km/s and compare with radial velocity > 290 km/s. Where do these objects appear on the HR diagram? Select ALL that apply.\n", "\n", "A) The low velocity objects appear roughly evenly distributed in color and magnitude.\n", "    \n", "B) The low velocity objects appear to be bluer (younger) stars.\n", "\n", "C) The low velocity objects appear to be redder (older) stars.\n", "\n", "D) The high velocity objects appear roughly evenly distributed in color and magnitude.\n", "\n", "E) The high velocity objects appear to be bluer (younger) stars.\n", "\n", "F) The high velocity objects appear to be redder (older) stars.\n", "\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "4d2f6f6b", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L25.1.2\n", "\n", "#DEFINE MASKS\n", "np.seterr(invalid=\"ignore\")\n", "\n", "lo_vel_mask = #YOUR CODE HERE\n", "hi_vel_mask = #YOUR CODE HERE\n", "\n", "hi_vel_color = 'tab:purple'\n", "lo_vel_color = 'tab:orange'\n", "hi_vel_label = 'high velocity'\n", "lo_vel_label = 'low velocity'\n", "\n", "#MAKE PLOT OF HR DIAGRAM\n", "#suggestion: use larger marker style or size to see clearly\n", "\n", "     "]}, {"cell_type": "markdown", "id": "b59e4c78", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_25_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\"> L25.2 Building Projections with Gaia </h2>  \n", "\n", "| [Top](#section_25_0) | [Previous Section](#section_25_1) | [Exercises](#exercises_25_2) | [Next Section](#section_25_3) |"]}, {"cell_type": "code", "execution_count": null, "id": "2f485591", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.2-runcell01\n", "\n", "H = gp.Hamiltonian(milky_way)\n", "w0_hi = gd.PhaseSpacePosition(galcen[hi_mass_mask].cartesian)\n", "w0_lo = gd.PhaseSpacePosition(galcen[lo_mass_mask].cartesian)\n", "\n", "orbits_hi = H.integrate_orbit(w0_hi, dt=1*u.Myr, t1=0*u.Myr, t2=500*u.Myr)\n", "orbits_lo = H.integrate_orbit(w0_lo, dt=1*u.Myr, t1=0*u.Myr, t2=500*u.Myr)\n", "\n", "w0_hlo,bin_edges = np.histogram(w0_lo.z.value,bins=10,density=True)\n", "w0_hhi,bin_edges = np.histogram(w0_hi.z.value,bins=bin_edges,density=True)\n", "bin_center = 0.5*(bin_edges[:-1] + bin_edges[1:])\n", "\n", "print(orbits_lo[-1,0],w0_lo[0])\n", "o0_hlo,bin_edges = np.histogram(1e3*orbits_lo[-1,:].z.value,bins=bin_edges,density=True)\n", "o0_hhi,bin_edges = np.histogram(1e3*orbits_hi[-1,:].z.value,bins=bin_edges,density=True)\n", "\n", "plt.plot(bin_center,w0_hlo,alpha=0.5,marker='.',drawstyle=\"steps-mid\",label='z-start low mass')\n", "plt.plot(bin_center,w0_hhi,alpha=0.5,marker='.',drawstyle=\"steps-mid\",label='z-start high mass')\n", "\n", "plt.plot(bin_center,o0_hlo,alpha=0.5,marker='.',drawstyle=\"steps-mid\",label='z-end low mass')\n", "plt.plot(bin_center,o0_hhi,alpha=0.5,marker='.',drawstyle=\"steps-mid\",label='z-end high mass')\n", "plt.legend()\n", "plt.xlabel('z[pc]')\n", "plt.ylabel('N')\n", "\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "5c092b81", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.2-runcell02\n", "\n", "fig = orbits_hi[0:500, 0].plot(color=hi_mass_color)\n", "_   = orbits_lo[0:500, 0].plot(axes=fig.axes, color=lo_mass_color)"]}, {"cell_type": "code", "execution_count": null, "id": "5625ab8c", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.2-runcell03\n", "\n", "plt.plot(1e-3*galcen[1==1].x.value, 1e-3*galcen[1==1].y.value,marker='.', linestyle='none', alpha=0.2,color='blue')\n", "plt.plot(1e-3*w0_lo.x.value,1e-3*w0_lo.y.value,marker='.', linestyle='none', alpha=0.5,color='green',label='start')\n", "plt.plot(orbits_lo[-1].x.value,orbits_lo[-1].y.value,marker='.', linestyle='none', alpha=0.5,color=lo_mass_color,label='low mass')\n", "plt.plot(orbits_hi[-1].x.value,orbits_hi[-1].y.value,marker='.', linestyle='none', alpha=0.5,color=hi_mass_color,label='high mass')\n", "plt.xlabel('x[kpc]')\n", "plt.ylabel('y[kpc]')\n", "plt.legend()\n", "plt.show()\n", "\n", "plt.plot(1e-3*galcen[1==1].z.value, 1e-3*galcen[1==1].y.value,marker='.', linestyle='none', alpha=0.2,color='blue')#,label='origin')\n", "plt.plot(1e-3*w0_lo.z.value,1e-3*w0_lo.y.value,marker='.', linestyle='none', alpha=0.5,color='green',label='start')\n", "plt.plot(orbits_lo[-1].z.value,orbits_lo[-1].y.value,marker='.', linestyle='none', alpha=0.5,color=lo_mass_color,label='low mass')\n", "plt.plot(orbits_hi[-1].z.value,orbits_hi[-1].y.value,marker='.', linestyle='none', alpha=0.5,color=hi_mass_color,label='high mass')\n", "plt.xlabel('z[kpc]')\n", "plt.ylabel('y[kpc]')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "61a67f66", "metadata": {"scrolled": false, "tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.2-runcell04\n", "\n", "fig = orbits_hi[:, 0].cylindrical.plot(['rho', 'z'], \n", "                                       color=hi_mass_color,\n", "                                       label='high mass')\n", "_ = orbits_lo[:, 0].cylindrical.plot(['rho', 'z'], color=lo_mass_color,\n", "                                     axes=fig.axes,\n", "                                     label='low mass')\n", "\n", "fig.axes[0].legend(loc='upper left')\n", "fig.axes[0].set_ylim(-0.3, 0.3)\n", "plt.show()\n", "\n", "plt.plot(1e-3*galcen[1==1].cylindrical.rho, 1e-3*galcen[1==1].z.value,marker='.', linestyle='none', alpha=0.2,color='blue')\n", "plt.plot(1e-3*w0_lo.cylindrical.rho,        1e-3*w0_lo.z.value,marker='.', linestyle='none', alpha=0.5,color='green')\n", "plt.plot(orbits_lo[-1].cylindrical.rho,orbits_lo[-1].z.value,marker='.', linestyle='none', alpha=0.5,color=lo_mass_color)\n", "plt.plot(orbits_hi[-1].cylindrical.rho,orbits_hi[-1].z.value,marker='.', linestyle='none', alpha=0.5,color=hi_mass_color)\n", "plt.xlabel(r'$\\rho$ [kpc]')\n", "plt.ylabel('z [kpc]')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "df4a17e2", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.2-runcell05\n", "\n", "zmax_hi = orbits_hi.zmax(approximate=True)\n", "zmax_lo = orbits_lo.zmax(approximate=True)\n", "bins = np.linspace(0, 2, 50)\n", "\n", "plt.hist(zmax_hi.value, bins=bins, alpha=0.4, density=True, label='high-mass', color=hi_mass_color)\n", "plt.hist(zmax_lo.value, bins=bins, alpha=0.4, density=True, label='low-mass',color=lo_mass_color);\n", "plt.legend(loc='best', fontsize=14)\n", "print(\"Mean high: \", zmax_hi.value.mean(),\"Mean Low:\",zmax_lo.mean())\n", "\n", "plt.yscale('log')\n", "plt.xlabel(r\" zmax\" + \" [{0:latex}]\".format(zmax_hi.unit))\n", "plt.show()\n", "\n", "zmax_hi = orbits_hi.eccentricity()\n", "zmax_lo = orbits_lo.eccentricity()\n", "print(\"Ecc high: \", zmax_hi.value.mean(),\"Ecc Low:\",zmax_lo.mean())\n", "\n", "bins = np.linspace(0, 2, 50) #bins = np.linspace(0, 0.75, 50)\n", "plt.hist(zmax_hi.value, bins=bins, alpha=0.4, density=True, label='high-mass', color=hi_mass_color)\n", "plt.hist(zmax_lo.value, bins=bins, alpha=0.4, density=True, label='low-mass',color=lo_mass_color);\n", "plt.legend(loc='best', fontsize=14)\n", "plt.yscale('log')\n", "plt.xlabel('Eccentricity')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "572fafab", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_25_2'></a>     \n", "\n", "| [Top](#section_25_0) | [Restart Section](#section_25_2) | [Next Section](#section_25_3) |\n"]}, {"cell_type": "markdown", "id": "e6a79be7", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 25.2.1</span>\n", "\n", "Let's make a histogram of another characteristic, namely the orbital period. Plot the distribution of orbital periods for these populations of stars. Note you will need the `estimate_period(radial=True)` function from <a href=\"https://gala.adrian.pw/en/latest/api/gala.dynamics.Orbit.html#gala.dynamics.Orbit.estimate_period\" target=\"_blank\">here</a>. \n", "\n", "As a rough measurement of how regular the periods are for each group, calculate the standard deviation of the orbital periods for the high-mass vs. low-mass stars. Report your answer as a list of numbers with `[per_hi_stdev,per_lo_stdev]`, with precision 1 Myr.\n", "\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "fe88cb92", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L25.2.1\n", "\n", "per_hi = #YOUR CODE HERE\n", "per_lo = #YOUR CODE HERE\n", "\n", "#CALCULATE THE STDEV OF EACH\n", "#YOUR CODE HERE\n", "\n", "#PLOT THE HISTOGRAM\n", "bins = np.linspace(100, 250, 50)\n", "plt.hist(per_hi.value, bins=bins, alpha=0.4, density=True, label='high-mass', color=hi_mass_color)\n", "plt.hist(per_lo.value, bins=bins, alpha=0.4, density=True, label='low-mass',color=lo_mass_color);\n", "plt.legend(loc='best', fontsize=14)\n", "plt.yscale('log')\n", "plt.xlabel('period')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "f7040e0a", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_25_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\"> L25.3 Anomaly Detection with Gaia </h2>  \n", "\n", "| [Top](#section_25_0) | [Previous Section](#section_25_2) | [Exercises](#exercises_25_3) | [Next Section](#section_25_4) |"]}, {"cell_type": "code", "execution_count": null, "id": "72c9793d", "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.3-runcell01\n", "\n", "def prepData(igaia_data,idist,igalcen,iSplit=0.5):\n", "    gaia_vars=['phot_g_mean_mag','phot_bp_mean_mag','phot_rp_mean_mag']\n", "    var0=(igaia_data[gaia_vars[0]]-idist.distmod).value\n", "    var1=(igaia_data[gaia_vars[1]]-idist.distmod).value\n", "    var2=(igaia_data[gaia_vars[2]]-idist.distmod).value\n", "    var3=igalcen.x.value\n", "    var4=igalcen.y.value\n", "    var5=igalcen.z.value\n", "    var6=igalcen.v_x.value\n", "    var7=igalcen.v_y.value\n", "    var8=igalcen.v_z.value\n", "\n", "    #processed_data = np.vstack((var0,var1,var2,var3,var4,var5,var6,var7,var8))\n", "    processed_data = np.vstack((var0,var1,var2,var3,var4,var5,var6,var7,var8))\n", "    processed_data = processed_data.T\n", "    processed_data = processed_data[~np.isnan(processed_data).any(axis=1)]\n", "    processed_data_raw = processed_data.copy()\n", "\n", "    #normalize the data\n", "    processed_data /= np.std(processed_data,axis=0)\n", "    processed_data -= np.mean(processed_data,axis=0)\n", "    processed_data = processed_data[~np.isnan(processed_data).any(axis=1)]\n", "    \n", "    #pytorch the layer\n", "    tprocessed_data = torch.tensor(processed_data).float()\n", "    processed_data_raw = processed_data_raw[~torch.any(tprocessed_data.isnan(),dim=1)]\n", "    galcen_clean       = igalcen[~torch.any(tprocessed_data.isnan(),dim=1)]\n", "    #split\n", "    maxindex       = int(len(processed_data)*iSplit)\n", "    trainset       = torch.tensor(processed_data[0:maxindex]).float()\n", "    trainset       = trainset[~torch.any(trainset.isnan(),dim=1)]\n", "    testset        = torch.tensor(processed_data[maxindex:len(processed_data)]).float()\n", "    testset        = testset[~torch.any(testset.isnan(),dim=1)]\n", "    print(processed_data_raw.shape,testset.shape,trainset.shape)\n", "    return testset,trainset,processed_data_raw,tprocessed_data,galcen_clean\n", "\n", "btestset,btrainset,bprocessed_data_raw,btprocessed_data,bgalcen_clean=prepData(gaia_data,dist,galcen)"]}, {"cell_type": "code", "execution_count": null, "id": "e6c8a4c7", "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.3-runcell02\n", "\n", "class MLP(nn.Module):\n", "    def __init__(self,n_inputs,n_outputs):\n", "        super(MLP, self).__init__()\n", "        self.layers = nn.Sequential(\n", "            nn.Linear(n_inputs, 20),\n", "            nn.ReLU(),\n", "            nn.Linear(20, 6),\n", "            nn.ReLU(),\n", "            nn.Linear(6, 2),\n", "            nn.ReLU(),\n", "            nn.Linear(2, 6),\n", "            nn.ReLU(),\n", "            nn.Linear(6, 20),\n", "            nn.ReLU(),\n", "            nn.Linear(20, n_outputs),\n", "        )\n", "        \n", "    def forward(self, x):        \n", "        x = self.layers(x)\n", "        return x\n", "\n", "def train(x,y,net,loss_func,opt,sched,nepochs):\n", "    net.train(True)\n", "    for epoch in range(nepochs):\n", "        prediction = net(x)\n", "        opt.zero_grad()\n", "        loss = loss_func(prediction,y) \n", "        loss.backward() \n", "        opt.step()\n", "        if epoch % 500 == 0: \n", "            print('[%d] loss: %.4f ' % (epoch + 1, loss.item()  ))\n", "    #sched.step()\n", "    return    \n", "\n", "basicmodel     = MLP(btrainset.shape[1],btrainset.shape[1])\n", "optimizer = torch.optim.Adam(basicmodel.parameters(), lr=0.01)\n", "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1, last_epoch=-1, verbose=False)\n", "loss_fn   =  nn.MSELoss(reduction='sum')"]}, {"cell_type": "code", "execution_count": null, "id": "03589744", "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.3-runcell03\n", "\n", "train(btrainset,btrainset,basicmodel,loss_fn,optimizer,scheduler,10001)"]}, {"cell_type": "code", "execution_count": null, "id": "a17ac6b8", "metadata": {"scrolled": false, "tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.3-runcell04\n", "\n", "basicmodel.train(False)\n", "boutput=basicmodel(btestset)\n", "btestloss=torch.sum((btestset-boutput)**2,axis=1)\n", "plt.hist(btestloss[btestloss < 100].detach().numpy(),density=True)\n", "plt.yscale('log')\n", "plt.xlabel('loss')\n", "plt.ylabel('pdf')\n", "plt.show()\n", "\n", "varlabels=['Mag','B-Mag','R-Mag','x','y','z','vx','vy','vz']\n", "\n", "fig, ax = plt.subplots(3, 3, figsize=(20, 20))\n", "for var in range(btestset.shape[1]):\n", "    _,bins,_=ax[var//3,var % 3].hist(btestset[:,var].detach().numpy(),density=True,alpha=0.5,label='Input')\n", "    ax[var//3,var % 3].hist(boutput [:,var].detach().numpy(),density=True,alpha=0.5,bins=bins,label='Output')\n", "    ax[var//3,var % 3].set_xlabel(varlabels[var])\n", "    ax[var//3,var % 3].legend()"]}, {"cell_type": "code", "execution_count": null, "id": "d60e7a03", "metadata": {"scrolled": false, "tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.3-runcell05\n", "\n", "def plotAnomaly(iCut,iRaw,iLoss,igalcen,maxlosscolor=20):\n", "    loss = np.minimum(iLoss,maxlosscolor)\n", "    anomalies=(iLoss > iCut)\n", "    baseidex=len(iRaw)-len(iLoss)\n", "    btestdata_raw = iRaw[baseidex:]\n", "    anomaly_raw  = btestdata_raw[anomalies]\n", "    btestgalcen   = igalcen[baseidex:]\n", "    anomaly_galcen = btestgalcen[anomalies]\n", "    loss = loss/np.max(loss)\n", "    if maxlosscolor != 20:\n", "        loss=np.ones(loss.shape)\n", "    print(loss.shape,btestdata_raw[:,2].shape)\n", "    scat=plt.scatter(btestdata_raw[:,2]-btestdata_raw[:,1],btestdata_raw[:,0], marker='.',c=loss,cmap=\"viridis\")\n", "    plt.plot(anomaly_raw[:,2]-anomaly_raw[:,1],anomaly_raw[:,0], marker='.', linestyle='none',c='orange')\n", "    plt.xlabel('$G_{BP}-G_{RP}$')\n", "    plt.ylabel('$M_{G}$')\n", "    plt.ylim(15,0)\n", "    plt.xlim(1,-5)\n", "    plt.colorbar(scat)\n", "    plt.show()\n", "    \n", "    scat=plt.scatter(btestdata_raw[:,3],btestdata_raw[:,4],c=loss, marker='.',cmap=\"viridis\")\n", "    plt.plot(anomaly_raw[:,3],anomaly_raw[:,4], marker='.', linestyle='none',c='orange')\n", "    plt.xlabel(\"x[pc]\")\n", "    plt.ylabel(\"y[pc]\")\n", "    plt.colorbar(scat)\n", "    plt.show()\n", "\n", "    scat=plt.scatter(btestdata_raw[:,3],btestdata_raw[:,5],c=loss, marker='.', cmap=\"viridis\")\n", "    plt.plot(anomaly_raw[:,3],anomaly_raw[:,5], marker='.', linestyle='none',c='orange')\n", "    plt.xlabel(\"x[pc]\")\n", "    plt.ylabel(\"z[pc]\")\n", "    plt.colorbar(scat)\n", "    plt.show()\n", "\n", "    scat=plt.scatter(btestdata_raw[:,6],btestdata_raw[:,7],c=loss, marker='.', cmap=\"viridis\")\n", "    plt.plot(anomaly_raw[:,6],anomaly_raw[:,7], marker='.', linestyle='none',c='orange')\n", "    plt.xlabel(\"vx[pc]\")\n", "    plt.ylabel(\"vy[pc]\")\n", "    plt.colorbar(scat)\n", "    plt.show()\n", "\n", "    scat=plt.scatter(btestdata_raw[:,6],btestdata_raw[:,8],c=loss, marker='.',cmap=\"viridis\")\n", "    plt.plot(anomaly_raw[:,6],anomaly_raw[:,8], marker='.', linestyle='none')\n", "    plt.xlabel(\"vx[pc]\")\n", "    plt.ylabel(\"vz[pc]\")\n", "    plt.show()\n", "\n", "    print(len(btestdata_raw),len(iRaw),len(igalcen),len(btestgalcen))\n", "    H = gp.Hamiltonian(milky_way)\n", "    w0_anom = gd.PhaseSpacePosition(anomaly_galcen.cartesian)\n", "    orbits_anom = H.integrate_orbit(w0_anom, dt=1*u.Myr, t1=0*u.Myr, t2=100*u.Myr)\n", "    w0_all  = gd.PhaseSpacePosition(bgalcen_clean[1==1].cartesian)\n", "    orbits_all  = H.integrate_orbit(w0_all,  dt=1*u.Myr, t1=0*u.Myr, t2=100*u.Myr)\n", "\n", "    zmax_all = orbits_all.zmax(approximate=True)\n", "    zmax_anom = orbits_anom.zmax(approximate=True)\n", "    print(\"ZMax mean:\",zmax_anom[~np.isnan(zmax_anom.value)].mean(),len(zmax_anom),\"default:\",zmax_all.mean())\n", "    bins = np.linspace(0, 10, 50)\n", "    plt.hist(zmax_all.value, bins=bins, alpha=0.4, density=True, label='all')\n", "    plt.hist(zmax_anom.value, bins=bins, alpha=0.4, density=True, label='anom')\n", "    plt.legend(loc='best', fontsize=14)\n", "    plt.yscale('log')\n", "    plt.xlabel(r\" zmax\" + \" [{0:latex}]\".format(zmax_all.unit))\n", "    plt.show()\n", "\n", "    zmax_all  = orbits_all.eccentricity()\n", "    zmax_anom = orbits_anom.eccentricity()\n", "    print(\"Ecc mean:\",zmax_anom[~np.isnan(zmax_anom.value)].mean(),len(zmax_anom),\"default:\",zmax_all.mean())\n", "    bins = np.linspace(0, 3, 50)\n", "    plt.hist(zmax_all.value,  bins=bins, alpha=0.4, density=True, label='all')\n", "    plt.hist(zmax_anom.value, bins=bins, alpha=0.4, density=True, label='anom')\n", "    plt.legend(loc='best', fontsize=14)\n", "    plt.yscale('log')\n", "    plt.xlabel('Eccentricity')\n", "    plt.show()\n", "\n", "\n", "plotAnomaly(10,bprocessed_data_raw,btestloss.detach().numpy(),bgalcen_clean)"]}, {"cell_type": "markdown", "id": "bed54b47", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_25_3'></a>     \n", "\n", "| [Top](#section_25_0) | [Restart Section](#section_25_3) | [Next Section](#section_25_4) |\n"]}, {"cell_type": "markdown", "id": "16860f69", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 25.3.1</span>\n", "\n", "We saw that anomalous stars tended to have large $|v_{x}|$ values. Let's try to cut on the events with $|v_{x}| > 100$ and thereby effectively reverse engineer the anomaly detection. \n", "\n", "In the function `plotAnomaly(iCut,iRaw,iLoss,igalcen,maxlosscolor=20)`, the anomalous objects have `iLoss` values that are above the threshold defined by `iCut`. So to accomplish our goal, let's define an array of `iLoss` values to be the velocities  $|v_{x}|$, then use the appropriate `iCut`.\n", "\n", "Consider the options below for defining this cut on the data, and choose the best one. Hint, look at the definitions within the `prepData` function at the beginning of this section.\n", "\n", "A) `cutvals=np.abs(bprocessed_data_raw[:,0][2032:]).copy()`\\\n", "B) `cutvals=np.abs(bprocessed_data_raw[:,1][2032:]).copy()`\\\n", "C) `cutvals=np.abs(bprocessed_data_raw[:,2][2032:]).copy()`\\\n", "D) `cutvals=np.abs(bprocessed_data_raw[:,3][2032:]).copy()`\\\n", "E) `cutvals=np.abs(bprocessed_data_raw[:,4][2032:]).copy()`\\\n", "F) `cutvals=np.abs(bprocessed_data_raw[:,5][2032:]).copy()`\\\n", "G) `cutvals=np.abs(bprocessed_data_raw[:,6][2032:]).copy()`\\\n", "H) `cutvals=np.abs(bprocessed_data_raw[:,7][2032:]).copy()`\\\n", "I) `cutvals=np.abs(bprocessed_data_raw[:,8][2032:]).copy()`\n", "\n", "\n", "Upon completing your selection above, try to run the code `plotAnomaly(100,bprocessed_data_raw,cutvals,bgalcen_clean,maxlosscolor=150)` and compare the HR diagram to what we saw before. Do you think this does a good job?\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "b6c127f9", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L25.3.1\n", "\n", "cutvals=#YOUR CODE HERE\n", "plotAnomaly(100,bprocessed_data_raw,cutvals,bgalcen_clean,maxlosscolor=150)"]}, {"cell_type": "markdown", "id": "9aabde57", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 25.3.2</span>\n", "\n", "Search for anomalies without using the red, blue, and general filters. Hint, to do this you could either redfine the `prepData` function, or perform the relavant selections on the existing data (e.g., `btestset[:,3:9]`). How do things compare? Select ALL that apply.\n", "\n", "A) The selected anomalies are identical.\n", "\n", "B) The selected anomalies are totally different.\n", "\n", "C) Some anomalies are the same, but the selection is different from before.\n", "\n", "D) The loss function is nearly identical.\n", "\n", "E) The loss function has a narrower tail, so fewer anomalies are selected.\n", "\n", "F) The loss function has a wider tail, so more anomalies are selected.\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "863cec5b", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_25_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\"> L25.4 Anomaly Detection with Lots of Gaia Data</h2>  \n", "\n", "| [Top](#section_25_0) | [Previous Section](#section_25_3) | [Exercises](#exercises_25_4) |"]}, {"cell_type": "code", "execution_count": null, "id": "a2a1092a", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.4-runcell01\n", "\n", "#note, our query looks for 1e6 stars, but only finds about 170k\n", "query_text = '''SELECT TOP 1000000 ra, dec, parallax, pmra, pmdec, radial_velocity,\n", "phot_g_mean_mag, phot_bp_mean_mag, phot_rp_mean_mag\n", "FROM gaiadr3.gaia_source\n", "WHERE parallax_over_error > 10 AND\n", "    parallax > 10 AND\n", "    radial_velocity IS NOT null\n", "ORDER BY random_index\n", "'''\n", "\n", "job = Gaia.launch_job(query_text)\n", "gaia_data = job.get_results()\n", "gaia_data.write('data/L25/gaia_data2.fits',overwrite=True)\n", "\n", "#Note, if you return to this section after closing the kernel,\n", "#you can load the data again using the following code\n", "gaia_data = QTable.read('data/L25/gaia_data2.fits')\n", "print(\"Total Events:\",len(gaia_data))\n"]}, {"cell_type": "code", "execution_count": null, "id": "a2d78a09", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.4-runcell02\n", "\n", "dist = coord.Distance(parallax=u.Quantity(gaia_data['parallax']))\n", "M_G = gaia_data['phot_g_mean_mag'] - dist.distmod\n", "BP_RP = gaia_data['phot_bp_mean_mag'] - gaia_data['phot_rp_mean_mag']\n", "\n", "plt.plot(BP_RP.value, M_G.value, marker='.', linestyle='none', alpha=0.3)\n", "\n", "plt.xlim(-1, 5)\n", "plt.ylim(17, -2)\n", "\n", "plt.xlabel('$G_{BP}-G_{RP}$')\n", "plt.ylabel('$M_{G}$')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "1726da7c", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.4-runcell03\n", "\n", "#redefine as above\n", "def prepData(igaia_data,idist,igalcen,iSplit=0.5):\n", "    gaia_vars=['phot_g_mean_mag','phot_bp_mean_mag','phot_rp_mean_mag']\n", "    var0=(igaia_data[gaia_vars[0]]-idist.distmod).value\n", "    var1=(igaia_data[gaia_vars[1]]-idist.distmod).value\n", "    var2=(igaia_data[gaia_vars[2]]-idist.distmod).value\n", "    var3=igalcen.x.value\n", "    var4=igalcen.y.value\n", "    var5=igalcen.z.value\n", "    var6=igalcen.v_x.value\n", "    var7=igalcen.v_y.value\n", "    var8=igalcen.v_z.value\n", "\n", "    #processed_data = np.vstack((var0,var1,var2,var3,var4,var5,var6,var7,var8))\n", "    processed_data = np.vstack((var0,var1,var2,var3,var4,var5,var6,var7,var8))\n", "    processed_data = processed_data.T\n", "    processed_data = processed_data[~np.isnan(processed_data).any(axis=1)]\n", "    processed_data_raw = processed_data.copy()\n", "\n", "    #normalize the data\n", "    processed_data /= np.std(processed_data,axis=0)\n", "    processed_data -= np.mean(processed_data,axis=0)\n", "    processed_data = processed_data[~np.isnan(processed_data).any(axis=1)]\n", "    \n", "    #pytorch the layer\n", "    tprocessed_data = torch.tensor(processed_data).float()\n", "    processed_data_raw = processed_data_raw[~torch.any(tprocessed_data.isnan(),dim=1)]\n", "    galcen_clean       = igalcen[~torch.any(tprocessed_data.isnan(),dim=1)]\n", "    #split\n", "    maxindex       = int(len(processed_data)*iSplit)\n", "    trainset       = torch.tensor(processed_data[0:maxindex]).float()\n", "    trainset       = trainset[~torch.any(trainset.isnan(),dim=1)]\n", "    testset        = torch.tensor(processed_data[maxindex:len(processed_data)]).float()\n", "    testset        = testset[~torch.any(testset.isnan(),dim=1)]\n", "    print(processed_data_raw.shape,testset.shape,trainset.shape)\n", "    return testset,trainset,processed_data_raw,tprocessed_data,galcen_clean\n", "\n", "c = coord.SkyCoord(ra=gaia_data['ra'], dec=gaia_data['dec'],distance=dist,pm_ra_cosdec=gaia_data['pmra'], pm_dec=gaia_data['pmdec'],\n", "                   radial_velocity=gaia_data['radial_velocity'])\n", "galcen = c.transform_to(coord.Galactocentric(z_sun=0*u.pc, galcen_distance=8.1*u.kpc))\n", "\n", "testset,trainset,processed_data_raw,tprocessed_data,galcen_clean=prepData(gaia_data,dist,galcen)"]}, {"cell_type": "code", "execution_count": null, "id": "ea4a2977", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.4-runcell04\n", "\n", "class MLP(nn.Module):\n", "    def __init__(self,n_inputs,n_outputs):\n", "        super(MLP, self).__init__()\n", "        self.layers = nn.Sequential(\n", "            nn.Linear(n_inputs, 100),\n", "            nn.ReLU(),\n", "            nn.Linear(100, 20),\n", "            nn.ReLU(),\n", "            nn.Linear(20, 4),\n", "            nn.ReLU(),\n", "            nn.Linear(4, 20),\n", "            nn.ReLU(),\n", "            nn.Linear(20, 100),\n", "            nn.ReLU(),\n", "            nn.Linear(100, n_outputs),\n", "        )\n", "        \n", "    def forward(self, x):        \n", "        x = self.layers(x)\n", "        return x\n", "\n", "def train(x,y,net,loss_func,opt,sched,nepochs):\n", "    net.train(True)\n", "    for epoch in range(nepochs):\n", "        prediction = net(x)\n", "        opt.zero_grad()\n", "        loss = loss_func(prediction,y) \n", "        loss.backward() \n", "        opt.step()\n", "        if epoch % 500 == 0: \n", "            print('[%d] loss: %.4f ' % (epoch + 1, loss.item()  ))\n", "    #sched.step()\n", "    return    \n", "\n", "model     = MLP(trainset.shape[1],trainset.shape[1])\n", "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n", "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1, last_epoch=-1, verbose=False)\n", "loss_fn   =  nn.MSELoss(reduction='sum')"]}, {"cell_type": "code", "execution_count": null, "id": "88cd12ea", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.4-runcell05\n", "\n", "train(trainset,trainset,model,loss_fn,optimizer,scheduler,10001)\n", "#train(trainset,trainset,model,loss_fn,optimizer,scheduler,5001) #train for shorter amount of epochs"]}, {"cell_type": "code", "execution_count": null, "id": "e58e17c2", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.4-runcell06\n", "\n", "model.train(False)\n", "output=model(testset)\n", "testloss=torch.sum((testset-output)**2,axis=1)\n", "plt.hist(testloss[testloss < 100].detach().numpy(),density=True)\n", "plt.yscale('log')\n", "plt.xlabel('loss')\n", "plt.ylabel('pdf')\n", "plt.show()\n", "\n", "varlabels=['Mag','B-Mag','R-Mag','x','y','z','vx','vy','vz']\n", "\n", "fig, ax = plt.subplots(3, 3, figsize=(20, 20))\n", "for var in range(testset.shape[1]):\n", "    _,bins,_=ax[var//3,var % 3].hist(testset[:,var].detach().numpy(),density=True,alpha=0.5,label='Input')\n", "    ax[var//3,var % 3].hist(output [:,var].detach().numpy(),density=True,alpha=0.5,bins=bins,label='Output')\n", "    ax[var//3,var % 3].set_xlabel(varlabels[var])\n", "    ax[var//3,var % 3].legend()"]}, {"cell_type": "code", "execution_count": null, "id": "907e3f37", "metadata": {"scrolled": false, "tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.4-runcell07\n", "\n", "milky_way = gp.MilkyWayPotential()\n", "H = gp.Hamiltonian(milky_way)\n", "w0_all  = gd.PhaseSpacePosition(galcen_clean[1==1].cartesian)\n", "orbits_all  = H.integrate_orbit(w0_all,  dt=1*u.Myr, t1=0*u.Myr, t2=100*u.Myr)\n", "#plotAnomaly(45,processed_data_raw,testloss,galcen_clean,orbits_all)"]}, {"cell_type": "code", "execution_count": null, "id": "82de276f", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.4-runcell08\n", "\n", "anomalies=(testloss > 45.)\n", "baseidex=len(processed_data_raw)-len(testloss)\n", "testgalcen   = galcen_clean[baseidex:]\n", "anomaly_galcen = testgalcen[anomalies]\n", "\n", "w0_anom = gd.PhaseSpacePosition(anomaly_galcen.cartesian)\n", "orbits_anom = H.integrate_orbit(w0_anom, dt=1*u.Myr, t1=0*u.Myr, t2=100*u.Myr)\n", "\n", "#redefine, as above\n", "hi_mass_color = 'tab:purple'\n", "lo_mass_color = 'tab:red'\n", "hi_mass_label = 'high mass'\n", "lo_mass_label = 'low mass'\n", "\n", "fig = orbits_all[0:200, 0].plot(color=hi_mass_color,label='normal')\n", "_   = orbits_all[0:200, 1].plot(axes=fig.axes,color=hi_mass_color)\n", "_   = orbits_all[0:200, 2].plot(axes=fig.axes,color=hi_mass_color)\n", "_   = orbits_anom[0:200, 0].plot(axes=fig.axes,label='anom 1')\n", "_   = orbits_anom[0:200, 1].plot(axes=fig.axes,label='anom 2')\n", "_   = orbits_anom[0:200, 2].plot(axes=fig.axes,label='anom 3')\n", "_   = orbits_anom[0:200, 3].plot(axes=fig.axes,label='anom 4',color=lo_mass_color)\n", "plt.legend()\n", "\n", "\n", "zmax=orbits_anom.zmax(approximate=True)\n", "print(zmax)"]}, {"cell_type": "code", "execution_count": null, "id": "21146213", "metadata": {"scrolled": false, "tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.4-runcell09\n", "\n", "def plotAnomalyBasic(iCut,iRaw,iLoss,igalcen,iOrbitsAll):\n", "    loss = np.minimum(iLoss.detach().numpy(),20)\n", "    anomalies=(iLoss > iCut)\n", "    baseidex=len(iRaw)-len(iLoss)\n", "    testdata_raw = iRaw[baseidex:]\n", "    anomaly_raw  = testdata_raw[anomalies]\n", "    testgalcen   = igalcen[baseidex:]\n", "    anomaly_galcen = testgalcen[anomalies]\n", "\n", "    scat=plt.scatter(-1.*(testdata_raw[:,2]-testdata_raw[:,1]),-1.*testdata_raw[:,0],c=loss)\n", "    plt.plot(-1.*(anomaly_raw[:,2]-anomaly_raw[:,1]),-1.*anomaly_raw[:,0], marker='.',c='orange', linestyle='none')\n", "    plt.xlabel('$G_{BP}-G_{RP}$')\n", "    plt.ylabel('$M_{G}$')\n", "    plt.colorbar(scat)\n", "    plt.show()\n", "\n", "    scat=plt.scatter(testdata_raw[:,3],testdata_raw[:,4], marker='.', c=loss)\n", "    plt.plot(anomaly_raw[:,3],anomaly_raw[:,4], marker='.',c='orange', linestyle='none')\n", "    plt.xlabel(\"x[pc]\")\n", "    plt.ylabel(\"y[pc]\")\n", "    plt.colorbar(scat)\n", "    plt.show()\n", "\n", "    scat=plt.scatter(testdata_raw[:,3],testdata_raw[:,5], marker='.', c=loss)\n", "    plt.plot(anomaly_raw[:,3],anomaly_raw[:,5], marker='.',c='orange', linestyle='none')\n", "    plt.xlabel(\"x[pc]\")\n", "    plt.ylabel(\"z[pc]\")\n", "    plt.colorbar(scat)\n", "    plt.show()\n", "\n", "    scat=plt.scatter(testdata_raw[:,6],testdata_raw[:,7], marker='.', c=loss)\n", "    plt.plot(anomaly_raw[:,6],anomaly_raw[:,7], marker='.',c='orange', linestyle='none')\n", "    plt.xlabel(\"vx[pc]\")\n", "    plt.ylabel(\"vy[pc]\")\n", "    plt.colorbar(scat)\n", "    plt.show()\n", "\n", "    scat=plt.scatter(testdata_raw[:,6],testdata_raw[:,8], marker='.', c=loss)\n", "    plt.plot(anomaly_raw[:,6],anomaly_raw[:,8], marker='.',c='orange', linestyle='none')\n", "    plt.xlabel(\"vx[pc]\")\n", "    plt.ylabel(\"vz[pc]\")\n", "    plt.colorbar(scat)\n", "    plt.show()\n", "\n", "def plotAnomalyComplex(iCut,iRaw,iLoss,igalcen,iOrbitsAll,iEccAll,iZAll,iT2):\n", "    anomalies=(iLoss > iCut)\n", "    baseidex=len(iRaw)-len(iLoss)\n", "    testdata_raw = iRaw[baseidex:]\n", "    anomaly_raw  = testdata_raw[anomalies]\n", "    testgalcen   = igalcen[baseidex:]\n", "    anomaly_galcen = testgalcen[anomalies]\n", "\n", "    print(len(testdata_raw),len(iRaw),len(igalcen),len(testgalcen))\n", "    H = gp.Hamiltonian(milky_way)\n", "    w0_anom = gd.PhaseSpacePosition(anomaly_galcen.cartesian)\n", "    orbits_anom = H.integrate_orbit(w0_anom, dt=1*u.Myr, t1=0*u.Myr, t2=iT2)\n", "\n", "    #zmax_all = iOrbitsAll.zmax(approximate=True)\n", "    zmax_anom = orbits_anom.zmax(approximate=True)\n", "    print(\"ZMax mean:\",zmax_anom[~np.isnan(zmax_anom.value)].mean(),len(zmax_anom),\"default:\",zmax_all.mean())\n", "    #print(zmax_anom,\"!! Anom 1\")\n", "    bins = np.linspace(0, 10, 50)\n", "    plt.hist(iZAll.value, bins=bins, alpha=0.4, density=True, label='all')\n", "    plt.hist(zmax_anom.value, bins=bins, alpha=0.4, density=True, label='anom')\n", "    plt.legend(loc='best', fontsize=14)\n", "    plt.yscale('log')\n", "    plt.xlabel(r\" zmax\" + \" [{0:latex}]\".format(zmax_all.unit))\n", "    plt.show()\n", "\n", "    #zmax_all  = orbits_all.eccentricity()\n", "    zmax_anom = orbits_anom.eccentricity()\n", "    print(\"Ecc mean:\",zmax_anom[~np.isnan(zmax_anom.value)].mean(),len(zmax_anom),\"default:\",zmax_all.mean())\n", "    bins = np.linspace(0, 10, 50)\n", "    plt.hist(iEccAll.value,  bins=bins, alpha=0.4, density=True, label='all')\n", "    plt.hist(zmax_anom.value, bins=bins, alpha=0.4, density=True, label='anom')\n", "    plt.legend(loc='best', fontsize=14)\n", "    plt.yscale('log')\n", "    plt.xlabel('Eccentricity')\n", "    plt.show()\n", "\n", "plotAnomalyBasic(45,processed_data_raw,testloss,galcen_clean,orbits_all)"]}, {"cell_type": "code", "execution_count": null, "id": "6fdeba0f", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L25.4-runcell10\n", "\n", "#Note, this will take some time to run\n", "zmax_all = orbits_all.zmax(approximate=True)\n", "ecc_all  = orbits_all.eccentricity()\n", "plotAnomalyComplex(20,processed_data_raw,testloss,galcen_clean,orbits_all,ecc_all,zmax_all,iT2=100*u.Myr)"]}, {"cell_type": "markdown", "id": "3be3073d", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_25_4'></a>     \n", "\n", "| [Top](#section_25_0) | [Restart Section](#section_25_4) |\n"]}, {"cell_type": "markdown", "id": "d622dc4a", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 25.4.1</span>\n", "\n", "We performed the analysis above using a multilayer perceptron (MLP). Consider what similarities or differences might arise if we instead used a variational autoencoder (VAE). Select ALL statements that accurately describe these machine learning methods.\n", "\n", "A) A VAE would provide a probabilistic representation of the data, while an MLP would provide a deterministic mapping from input to output.\n", "\n", "B) Both VAE and MLP can be used for anomaly detection, but a VAE can generate new samples similar to the training data, which an MLP cannot do.\n", "\n", "C) A VAE would learn a continuous latent space, while an MLP would not.\n", "\n", "\n", "**Afterwards, perform the same analysis as above with a VAE, using 4 latent dimensions.** What do you find? Note, you can check the solution to this problem to see the code that we used.\n", "\n", "<br>"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}